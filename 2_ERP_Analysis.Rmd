---
title: "ERP Analysis"
output: 
  html_document

---

<!-- Set general settings -->

```{r setup, include = FALSE}

# Set general settings for markdown file
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = "",
  results = "hold"
)


# Clear environment
rm(list = ls())


# Enable/disable caching of time-consuming code chunks
knitr_cache_enabled = TRUE


# Load packages
library(dplyr)      # for data manipulation
library(knitr)      # for integrating computing and reporting in markdown
library(kableExtra) # for customizing appearance of tables
library(ggplot2)    # for plotting
library(cowplot)    # for arranging plots
library(e1071)      # for functions skewness and kurtosis
library(MASS)       # for boxcox function and contrast definition
library(lme4)       # for (G)LMMs
library(lmerTest)   # for LMM p values (Satterthwaite's method for approximating dfs for the t and F tests)
library(sjPlot)     # for tab_model function to display (G)LMM results
library(performance)# for check of model various assumptions
library(influence.ME) # to calculate Cook's distance
library(emmeans)    # for pairwise comparisons
library(afex)       # for ANOVAs (convenience functions, e.g. for nice display)
library(effectsize) # for effect sizes (t_to_d function)
library(tidyr)      # for reshape function
library(readr)      # for raincloud plots
library(lavaan)     # for raincloud plots
library(splithalf)  # for permutation-based split-half reliability


# Load functions
source("./functions/summarySEwithinO.R")  # Function provided by R-cookbook: http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/
source("./functions/my_table_template.R") # Function to create table template
source("./functions/R_rainclouds.R")      # Function to create raincloud plots


# Turn off scientific notation
options(scipen = 999)


# Set figure theme and colors
my_figure_theme <- theme_classic(base_size = 11) +
  theme(legend.position = "bottom", 
        strip.background = element_rect(fill="grey95", linetype = "blank"),
        axis.ticks.x = element_blank(), 
        plot.title = element_text(hjust = 0.5)) 
# instad of theme_classic: + theme_apa(base_size = 11)

my_figure_colors <- c("#8ea6b4", "#465369")
```
<br><br> 

## Data Cleaning
***

```{r load-and-clean-data, cache = knitr_cache_enabled}

# Load data
load(file = "./data/Single_Trial_Data.rda")
load(file = "./data/Feedback_Infos.rda")


# Exclude P_02 (due to retainer) and C_02 (as preregistered: patients are excluded with their match)
single_trial_data <- single_trial_data[single_trial_data$participant_id != "P_02" & single_trial_data$participant_id != "C_02",]
feedback_infos    <- feedback_infos[feedback_infos$participant_id != "P_02" & feedback_infos$participant_id != "C_02",]


# Exclude missing responses, RT outliers and trials with ERP artifacts
single_trial_data_clean <- single_trial_data %>%
  dplyr::filter(
      response_type != "miss" &
      rt_invalid  == FALSE &
      !is.na(MFN_0_100_FCz)
  ) # (53093 of 55680 trials left)


# Add column for (grand mean centered) number of errors (needed as covariate later) - this variable contains total number of errors, not only those entering analysis (preferred according to JK)
single_trial_data_clean <- single_trial_data %>% 
  dplyr::group_by(participant_id, session) %>% 
  dplyr::summarize(number_errors = sum(response_type == "incorrect")) %>%
  dplyr::ungroup(.) %>%
  dplyr::left_join(single_trial_data_clean, ., by = c("participant_id", "session")) 
# Standardize this variable
single_trial_data_clean$number_errors_standardized <- scale(single_trial_data_clean$number_errors, center = TRUE, scale = TRUE)


# Add column for (grand mean centered) number of speeding (needed as covariate later) 
single_trial_data_clean <- feedback_infos[feedback_infos$block != 6,] %>% 
  dplyr::group_by(participant_id, session, feedback) %>%
  dplyr::count(feedback, .drop = FALSE) %>%
  dplyr::filter(feedback == " schneller") %>%
  dplyr::rename(number_feedback_faster = n) %>%
  dplyr::ungroup(.) %>%  
  dplyr::select(-feedback) %>%
  dplyr::left_join(single_trial_data_clean, ., by = c("participant_id", "session"))  
# Standardize this variable
single_trial_data_clean$number_feedback_faster_standardized <- scale(single_trial_data_clean$number_feedback_faster, center = TRUE, scale = TRUE)


# Add column for medication (needed as covariate later) 
single_trial_data_clean <- single_trial_data_clean %>% 
  dplyr::mutate(medication = as.factor(ifelse(participant_id == "P_02" | participant_id == "P_04" | participant_id == "P_05" |
                                              participant_id == "P_06" | participant_id == "P_08" | participant_id == "P_10" |
                                              participant_id == "P_15" | participant_id == "P_16" | participant_id == "P_18" |
                                              participant_id == "P_22" | participant_id == "P_25" | participant_id == "P_26" |
                                              participant_id == "P_28" | participant_id == "P_30", "yes", "no")))


# Add column for (within-subject mean centered) baseline EEG (needed as covariate later) 
single_trial_data_clean <- single_trial_data_clean %>% 
  dplyr::group_by(participant_id, session) %>%
  dplyr::mutate(
    MFN_baseline_pre_200_0_FCz_standardized = scale(MFN_baseline_pre_200_0_FCz, center = TRUE, scale = TRUE),
    Pe_baseline_pre_200_0_Pz_standardized   = scale(Pe_baseline_pre_200_0_Pz, center = TRUE, scale = TRUE))  %>%
  dplyr::ungroup()


# Calculate aggregated data per subject for boxplots, ANOVAs, t tests, and outlier detection
df_aggregated_per_subject_MFN <- single_trial_data_clean %>%
  dplyr::group_by(participant_id, group, response_type, stimulation, session) %>%
  dplyr::summarize(
    MFN = mean(MFN_0_100_FCz, na.rm = TRUE)
   )  %>%
  dplyr::ungroup()


# Calculate aggregated data per subject for ANOVA on 
# a) difference incorrect - correct mean amplitude (0 to 100 ms at FCz)
# b) difference incorrect - correct mean area (-50 to 150 ms at FCz) as described by Reinhart & Woodman (2014)
df_aggregated_per_subject_MFN_diff <- single_trial_data_clean %>%
  dplyr::group_by(participant_id, group, stimulation, session) %>%
  dplyr::summarize(
    MFN_correct        = mean(MFN_0_100_FCz[response_type == "correct"], na.rm = TRUE),
    MFN_incorrect      = mean(MFN_0_100_FCz[response_type == "incorrect"], na.rm = TRUE),
    MFN_correct_area   = mean(MFN_area_pre_50_150_FCz[response_type == "correct"], na.rm = TRUE),
    MFN_incorrect_area = mean(MFN_area_pre_50_150_FCz[response_type == "incorrect"], na.rm = TRUE)
    ) %>%
  dplyr::mutate(
    MFN_incorrect_minus_correct      = MFN_incorrect      - MFN_correct,
    MFN_incorrect_minus_correct_area = MFN_incorrect_area - MFN_correct_area
  )  %>%
  dplyr::ungroup()


# Make categorical variables factors
single_trial_data_clean$participant_id      <- as.factor(single_trial_data_clean$participant_id) 
single_trial_data_clean$group               <- as.factor(single_trial_data_clean$group)
single_trial_data_clean$session             <- as.factor(single_trial_data_clean$session)
single_trial_data_clean$stimulation         <- as.factor(single_trial_data_clean$stimulation)
single_trial_data_clean$stimulus_type       <- as.factor(single_trial_data_clean$stimulus_type)
single_trial_data_clean$response_type       <- as.factor(single_trial_data_clean$response_type)
```

Trials were excluded from all analyses if RT was shorter than 100 ms or longer than 800 ms or if the response in a trial was missing. We further discarded trials containing artifacts in the EEG, i.e., a voltage difference exceeding 50 μV between two consecutive sampling points or 200 μV within an epoch. 

```{r excluded-trials}

# Calculate percentage of excluded trials per group
excluded_trials_per_participant <- single_trial_data %>%
  dplyr::group_by(group, participant_id, session) %>%
  dplyr::summarize(
    invalid_rt   = sum(!is.na(rt_invalid) & rt_invalid != FALSE) / length(participant_id) * 100,
    misses       = sum(response_type == "miss") / length(participant_id) * 100,
    EEG_artifact = sum(is.nan(MFN_0_100_FCz)) / length(participant_id) * 100
   )  %>%
  dplyr::ungroup() %>%
  dplyr::group_by(group) %>%
  # Calculate M and SD of the variables
  dplyr::summarize(across(-c(participant_id, session), list(mean,sd,min,max)))  %>%
  dplyr::ungroup()


# Display percentage of excluded trials per group
my_table_template(excluded_trials_per_participant,
  caption = "Excluded Trials (M and SD in %) Mean per Group", 
  col_names = c("Group", "M", "SD", "min", "max", "M", "SD", "min", "max", "M", "SD", "min", "max"),
  header_above_config = c(" " = 1, "RT < 100 / > 800 ms" = 4, "Misses" = 4, "EEG artifact" = 4)
)


# Calculate percentage of excluded trials in total
excluded_trials_in_total <- single_trial_data %>%
  dplyr::summarize(
    invalid_rt   = sum(!is.na(rt_invalid) & rt_invalid != FALSE) / nrow(single_trial_data) * 100,
    misses       = sum(response_type == "miss") / nrow(single_trial_data) * 100,
    EEG_artifact = sum(is.nan(MFN_0_100_FCz)) / nrow(single_trial_data) * 100
   )


# Display percentage of excluded trials in total
my_table_template(excluded_trials_in_total,
  caption = "Excluded Trials (in %) in Total") 


# Detect ERP outliers (ERP deviates more than 2/3 SD below/above group mean per condition)
ERP_outliers <- df_aggregated_per_subject_MFN %>% 
  dplyr::group_by(group, response_type, stimulation) %>%
  dplyr::mutate(outlier_2_sd = case_when(abs(MFN - mean(MFN, na.rm = TRUE)) <=  2 * sd(MFN, na.rm = TRUE)~ FALSE, TRUE ~ TRUE),
                outlier_3_sd = case_when(abs(MFN - mean(MFN, na.rm = TRUE)) <=  3 * sd(MFN, na.rm = TRUE)~ FALSE, TRUE ~ TRUE)) %>%
  dplyr::filter(outlier_2_sd == TRUE)  %>%
  dplyr::ungroup()


# Display ERP outliers
my_table_template(ERP_outliers, caption = "ERP outliers (> 2/3 SD below/above group mean per condition (response type x stimulation))")
```
There is one participant (P_28) whose ERN deviates > 3 SD from the group mean per condition (response type x stimulation). This participant is also quite prominent in the raincloud plot and line plot (see below). There are a few participants whose ERN deviates > 2 SD. I did not exclude participants based on this criterion. Being an outlier in ERP magnitude is also no exclusion criterion specified in the preregistration. 
<br><br>

## Data Inspection {.tabset}
***

### Distribution

```{r inspect-distribution, cache = knitr_cache_enabled}

# Plot distribution MFN
hist_MFN <- ggplot(single_trial_data_clean, aes(x = MFN_0_100_FCz)) +
  geom_histogram(aes(y = ..density..), color="gray33", fill = "#8ea6b4", size = 1) +
  stat_function(fun = dnorm, args=list(mean = mean(single_trial_data_clean$MFN_0_100_FCz, na.rm = TRUE), 
                                     sd = sd(single_trial_data_clean$MFN_0_100_FCz, na.rm = TRUE)), color = "black", size = 0.5) +
  geom_vline(aes(xintercept = mean(MFN_0_100_FCz, na.rm = TRUE)), color = "black", linetype = "dashed", size = 1) +
  labs (title = "Histogram MFN", x = "MFN", y = "Density") + 
  my_figure_theme 

qqplot_MFN <- ggplot(single_trial_data_clean, aes(sample = MFN_0_100_FCz)) +
  stat_qq(color = "#8ea6b4") +
  stat_qq_line() +
  labs (title = "Q-Q-Plot MFN", x = "Theoretical Quantiles", y = "Sample Quantiles") + 
  my_figure_theme


# Plot distribution ERN
hist_ERN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",], aes(x = MFN_0_100_FCz)) +
  geom_histogram(aes(y = ..density..), color="gray33", fill = "#8ea6b4", size = 1) +
  stat_function(fun = dnorm, args=list(mean = mean(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz, na.rm = TRUE), 
                                     sd = sd(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz, na.rm = TRUE)), color = "black", size = 0.5) +
  geom_vline(aes(xintercept = mean(MFN_0_100_FCz, na.rm = TRUE)), color = "black", linetype = "dashed", size = 1) +
  labs (title = "Histogram ERN", x = "ERN", y = "Density") + 
  my_figure_theme

qqplot_ERN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",], aes(sample = MFN_0_100_FCz)) +
  stat_qq(color = "#8ea6b4") +
  stat_qq_line() +
  labs (title = "Q-Q-Plot ERN", x = "Theoretical Quantiles", y = "Sample Quantiles") + 
  my_figure_theme


# Plot distribution CRN
hist_CRN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "correct",], aes(x = MFN_0_100_FCz)) +
  geom_histogram(aes(y = ..density..), color="gray33", fill = "#8ea6b4", size = 1) +
  stat_function(fun = dnorm, args=list(mean = mean(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz, na.rm = TRUE), 
                                     sd = sd(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz, na.rm = TRUE)), color = "black", size = 0.5) +
  geom_vline(aes(xintercept = mean(MFN_0_100_FCz, na.rm = TRUE)), color = "black", linetype = "dashed", size = 1) +
  labs (title = "Histogram CRN", x = "CRN", y = "Density") + 
  my_figure_theme

qqplot_CRN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "correct",], aes(sample = MFN_0_100_FCz)) +
  stat_qq(color = "#8ea6b4") +
  stat_qq_line() +
  labs (title = "Q-Q-Plot CRN", x = "Theoretical Quantiles", y = "Sample Quantiles") + 
  my_figure_theme

ggdraw() +
  draw_plot(hist_MFN,       x =  0,   y = .66,   width = .5, height = .33) +
  draw_plot(qqplot_MFN,     x =  .5,  y = .66,   width = .5, height = .33) +
  draw_plot(hist_ERN,       x =  0,   y = .33,   width = .5, height = .33) +
  draw_plot(qqplot_ERN,     x =  .5,  y = .33,   width = .5, height = .33) +
  draw_plot(hist_CRN,       x =  0,   y = 0,     width = .5, height = .33) +
  draw_plot(qqplot_CRN,     x =  .5,  y = 0,     width = .5, height = .33) 
```
<br><br>

### ERN/CRN per participant 

```{r plot-RT-per-subject-and-response-type, fig.width = 12, fig.height = 20, cache = knitr_cache_enabled}

MFN_per_participant <- ggplot(single_trial_data_clean, aes(x = response_type, y = MFN_0_100_FCz, group = response_type)) + 
  geom_point(aes(fill = response_type), color = "black", shape = 21, position = "jitter") + 
  ggtitle("MFN per participant") + 
  my_figure_theme + 
  facet_wrap(~ participant_id + stimulation, ncol = 10) +
  scale_fill_manual(values = my_figure_colors) 
MFN_per_participant
```
<br><br>

### Check Normality 

For the single-trial data, Shapiro-Wilk is not suitable, as it always returns a significant result for such large samples (additionally, it can handle only samples up to 5000). Hence, we have to rely on visual inspection (see tab "Distribution") and values of skewness and kurtosis (see below). Values for skewness and kurtosis between -2 and +2 are considered acceptable in order to prove normal univariate distribution (George & Mallery, 2010).

```{r normality-single-trial-MFN}

normality_MFN <- round(data.frame(matrix(c(skewness(single_trial_data_clean$MFN_0_100_FCz),
                                          kurtosis(single_trial_data_clean$MFN_0_100_FCz),
                                          skewness(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz),
                                          kurtosis(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz),
                                          skewness(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz),
                                          kurtosis(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz)),
                                        nrow=2, ncol = 3)),digits = 1)
rownames(normality_MFN) <- c("Skewness","Kurtosis")
colnames(normality_MFN) <- c("MFN", "ERN", "CRN")

my_table_template(normality_MFN, row_names = TRUE)
```
<br><br>

### Determine transformation

LMM analysis of MFN/ERN/CRN will be conducted on untransformed values, as it seems that the assumption of normally distributed residuals will be met. The appropriate transformation was determined using the Box–Cox procedure (Box & Cox, 1964). 

```{r MFN-determine-transformation, fig.width = 8, fig.height = 3}

# Arrange plots
par(mfrow = c(1, 3)) 

# Determine transformation of MFN by estimating optimal lambda using Box–Cox procedure
bc_MFN <- boxcox(MFN_0_100_FCz + 100 ~ 1, data = single_trial_data_clean)
optlambda_MFN <- bc_MFN$x[which.max(bc_MFN$y)]

# Determine transformation of ERN by estimating optimal lambda using Box–Cox procedure
bc_ERN <- boxcox(MFN_0_100_FCz + 100 ~ 1, data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",])
optlambda_ERN <- bc_ERN$x[which.max(bc_ERN$y)]

# Determine transformation of CRN by estimating optimal lambda using Box–Cox procedure
bc_CRN <- boxcox(MFN_0_100_FCz + 100 ~ 1, data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",])
optlambda_CRN <- bc_CRN$x[which.max(bc_CRN$y)]

# Reset plot layout
par(mfrow = c(1, 1)) 
```
For MFN (left plot), the optimal lambda is `r round(optlambda_MFN, digits = 2)`, suggesting that no transformation (for lambda = 1) is needed.
For ERN (middle plot), the optimal lambda is `r round(optlambda_ERN, digits = 2)`, suggesting that no transformation (for lambda = 1) is needed.
For CRN (right plot), the optimal lambda is `r round(optlambda_CRN, digits = 2)`, suggesting that no transformation (for lambda = 1) is needed.
<br><br>

### Split-half reliability

```{r permutation-split-half-reliability, cache = knitr_cache_enabled}

# Calculate permutation-based split-half internal consistency
# use ""invisible(capture.output())" to avoid having ugly console output in html
invisible(capture.output(split_half_reliability <- splithalf(data = single_trial_data_clean,
                                    outcome = "RT",
                                    score = "average",
                                    permutations = 5000,
                                    halftype = "random",
                                    var.RT = "MFN_0_100_FCz",
                                    var.trialnum = "trial",
                                    var.participant = "participant_id",
                                    var.condition = "response_type",
                                    conditionlist = c("correct","incorrect"),
                                    average = "mean")))

# Display permutation-based split-half internal consistency
my_table_template(split_half_reliability$final_estimates, caption = "Permutation-based split-half reliability")
```
The internal consitency of ERN and CRN was estimated using a permutation-based split-half approach (Parsons 2020) with 5000 random splits. The (Spearman-Brown corrected) split-half internal consistency of ERN and CRN are excellent. The columns SB_low and SB_high represent 95% confience intervall limits. The spearman-brown corrected reliability estimate for the ERN was .95, 95% CI [.93, .97], for CRN 1, 95% CI [.99, 1]. The splithalf package was built to deal with RTs. However, the principle should also apply to ERP values, so the results should be correct. However, I also calculated the odd-even split-half reliabilty to compare the results (see below).
<br><br>

```{r odd-even-split-half-reliability}

# Code odd and even trials for reliability 
single_trial_data_clean$oddeven <- single_trial_data_clean$trial %% 2
single_trial_data_clean$oddeven <- single_trial_data_clean$trial %% 2


# Calculate mean CRN for odd and even trials per participant and session
internal_consistency_CRN <- single_trial_data_clean[single_trial_data_clean$response_type == "correct",] %>%
  dplyr::group_by(participant_id, session, oddeven) %>% 
  dplyr::summarise(mean_CRN = mean(MFN_0_100_FCz, na.rm=TRUE)
)  %>%
  dplyr::ungroup()


# Calculate mean ERN for odd and even trials per participant and session
internal_consistency_ERN <- single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",] %>%
  dplyr::group_by(participant_id, session, oddeven) %>% 
  dplyr::summarise(mean_ERN = mean(MFN_0_100_FCz, na.rm=TRUE)
)  %>%
  dplyr::ungroup()


# Correlating scores from even and odd items
r_CRN <- cor.test(internal_consistency_CRN$mean_CRN[internal_consistency_CRN$oddeven==1], internal_consistency_CRN$mean_CRN[internal_consistency_CRN$oddeven==0])
r_ERN <- cor.test(internal_consistency_ERN$mean_ERN[internal_consistency_ERN$oddeven==1], internal_consistency_ERN$mean_ERN[internal_consistency_ERN$oddeven==0])


# Adjusting with the Spearman-Brown prophecy formula
r_CRN_SB <- (2 * r_CRN$estimate) / (1 + r_CRN$estimate)
r_ERN_SB <- (2 * r_ERN$estimate) / (1 + r_ERN$estimate)


# Display odd-even split-half reliability
oddeven_split_half_reliability <- matrix(c(r_CRN$estimate, r_ERN$estimate, r_CRN$conf.int[1], r_ERN$conf.int[1], 
                                           r_CRN$conf.int[2], r_ERN$conf.int[2], r_CRN_SB, r_ERN_SB), ncol=4)
colnames(oddeven_split_half_reliability) <- c("splithalf_raw", "splithalf_CI_lower_limit", "splithalf_CI_upper_limit", "splithalf_spearmanbrown")
rownames(oddeven_split_half_reliability) <- c("CRN", "ERN")
my_table_template(oddeven_split_half_reliability, row_names = TRUE, caption = "Odd-even split-half reliability")
```
Odd-even reliability for the ERN is also good. 
<br><br>

## Descriptive Statistics {.tabset}
***

### Means and CIs

```{r descriptive-statistics-table}

# Calculate descriptive statistics for MFN per condition
descriptive_statistics_MFN <- summarySEwithinO(
  data          = single_trial_data_clean,
  measurevar    = "MFN_0_100_FCz",
  withinvars    = c("response_type", "stimulation", "session"),
  betweenvars   = "group",
  idvar         = "participant_id", 
  conf.interval = .95) %>%
  # Format confidence interval column
  dplyr::mutate(
    ci_MFN = paste0("[", round(MFN_0_100_FCz - ci, digits = 2), 
                   ", ", round(MFN_0_100_FCz + ci, digits = 2), "]")) %>%
  # Round MFN means to two decimals
  dplyr::mutate_at("MFN_0_100_FCz", round, digits = 2) %>%    
  # Select columns to be displayed
  dplyr::select(c("group", "response_type", "stimulation", "session", "MFN_0_100_FCz", "ci_MFN", "ci"))



# Split and re-merge MFN table to display both groups next to each other
descriptive_statistics_MFN_display <-  split(descriptive_statistics_MFN, descriptive_statistics_MFN$group)
descriptive_statistics_MFN_display <-  left_join(descriptive_statistics_MFN_display$HC, descriptive_statistics_MFN_display$OCD, 
                                                 by = c("response_type", "stimulation", "session"))


# Display descriptive statistics for MFN (and select columns)
my_table_template(descriptive_statistics_MFN_display[,c(2:6,9:10)],
  caption = "MFN (in μV)",
  col_names = c("Response type", "Stimulation", "Session", "M", "95% CI", "M", "95% CI"),
  header_above_config = c(" " = 3, "HC" = 2, "OCD" = 2),
  footnote_config = c(general = "Confidence intervals are adjusted for within-participant designs as described by Morey (2008).")
)



# Calcuate means and CIs adjusted for within-participant factors (without session) - for plots
descriptive_statistics_MFN_no_session <- summarySEwithinO(
  data          = single_trial_data_clean,
  measurevar    = "MFN_0_100_FCz",
  withinvars    = c("response_type", "stimulation"),
  betweenvars   = "group",
  idvar         = "participant_id", 
  conf.interval = .95
)
```
<br><br>

### Raincloud plot {.active}

```{r raincloud-plot, fig.width = 10, fig.height = 6, fig.cap = "Note. Response-locked ERP (ERN, CRN; 0-100 ms at FCz) in the flanker task is shown as a function of response type, stimulation condition, and group. Means and 95% confidence intervals (= lines at violin plot bottom) were calculated based on single-trial data. Boxplots and violin plots are based on data aggregated by participant. CIs are adjusted for within-participant designs as described by Morey (2008)."}


# Define facet labels
response_type.labs <- c("CRN", "ERN")
names(response_type.labs) <- c("correct", "incorrect")


# From JB: "Raincloud plots (Allen et al., 2019) show means and 95% CIs calculated with the summarySEwithin function (Morey, 2008) on single trial data, and points, and distributions for data aggregated by subject"

# Create raincloud plot MFN 
plot_MFN_raincloud <- ggplot() +
  # Add aggregated distribution, boxplot and data points
  geom_flat_violin(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group), position = position_nudge(x = .1, y = 0), 
                   adjust = 1.5, trim = FALSE, alpha = .5, colour = NA)+
  geom_point(data = df_aggregated_per_subject_MFN, aes(x = as.numeric(stimulation)-.15, y = MFN, colour = group),
             position = position_jitter(width = .05), size = 1, shape = 20)+
  geom_boxplot(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group),
               outlier.shape = NA, alpha = .5, width = .1, colour = "black")+
  # Add single-trial mean + CI
  geom_point(data = descriptive_statistics_MFN_no_session, aes(x = as.numeric(stimulation)+0.1, y = MFN_0_100_FCz, colour = group), 
             shape = 95, size = 6) +
  geom_errorbar(data = descriptive_statistics_MFN_no_session, aes(x = as.numeric(stimulation)+0.1, ymax = MFN_0_100_FCz + ci, ymin = MFN_0_100_FCz - ci), 
                colour = "black", width = 0) +
  # Add style
  scale_colour_manual(values = my_figure_colors, name = "Group:") +
  scale_fill_manual(values = my_figure_colors, name = "Group:") +
  facet_wrap(~response_type,labeller = labeller(response_type = response_type.labs)) + 
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])") +
  my_figure_theme 


# Save plot
 ggsave("./figures/figure_MFN_raincloud.tiff", width = 20, height = 25, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN_raincloud
```
<br><br>

### Line plot participant-wise

```{r line-plot, fig.height = 9, fig.width = 6}

# Define facet labels
response_type.labs <- c("CRN", "ERN")
names(response_type.labs) <- c("correct", "incorrect")


# Create line plot MFN 
plot_MFN_lines <- ggplot(df_aggregated_per_subject_MFN, aes(x=stimulation, y=MFN, group=participant_id)) +
  geom_point(aes(colour=group), size=4.5, position=position_dodge(width=0.1)) +
  geom_line(size=0.5, alpha=0.5, position=position_dodge(width=0.1)) +
  # Add style
  scale_colour_manual(values = my_figure_colors, guide=FALSE) +
  facet_grid(cols = vars(response_type), rows = vars(group), scales = "free",labeller = labeller(response_type = response_type.labs))+
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])") +
  my_figure_theme 


# Save plot
ggsave("./figures/figure_MFN_lines.tiff", width = 13, height = 18, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN_lines
```
<br><br>

### Plot without session

```{r descriptive-statistics-plot-rt-acc, fig.width = 8, fig.height = 7, fig.cap = "Note. Response-locked ERP (ERN, CRN; 0-100 ms at FCz) in the flanker task is shown as a function of response type, stimulation condition, and group. Means and 95% confidence intervals (shown in orange/red) were calculated based on single-trial data. Boxplots are based on data aggregated by participant. CIs are adjusted for within-participant designs as described by Morey (2008)."}

# Create plot MFN 
plot_MFN <- ggplot() +
  geom_boxplot(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group), outlier.size =0.3)+
  geom_point(data = descriptive_statistics_MFN_no_session, aes(x = stimulation, y = MFN_0_100_FCz, colour = group), 
             position = position_dodge(width = 0.7), shape = 15, size = 1) +
  geom_errorbar(data = descriptive_statistics_MFN_no_session, aes(x = stimulation, ymax = MFN_0_100_FCz + ci, ymin = MFN_0_100_FCz - ci, colour = group),
                position = position_dodge(width = 0.7), width = 0, size = 0.5) +
  geom_line(data = descriptive_statistics_MFN_no_session, aes(x = stimulation, y = MFN_0_100_FCz, group = group, color = group), 
            position = position_dodge(width = 0.7), linetype = 3, size = 0.5) +
  scale_colour_manual(values = c("#b23f00", "#ff9b64"), name = "Group:") +
  scale_fill_manual(values = my_figure_colors, name = "Group:") +
  facet_wrap(~response_type, nrow = 1) +
  my_figure_theme + 
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])")


# Save plot
ggsave("./figures/figure_MFN.tiff", width = 12, height = 12, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN
``` 
<br><br>

### Plot with session

```{r descriptive-statistics-plot-including-session, fig.width = 10, fig.height = 7, fig.cap = "Note. Response-locked ERP (ERN, CRN; 0-100 ms at FCz) in the flanker task is shown as a function of response type, stimulation condition, group, and session. Means and 95% confidence intervals (shown in orange/red) were calculated based on single-trial data. Boxplots are based on data aggregated by subject. CIs are adjusted for within-participant designs as described by Morey (2008)."}

# Create plot MFN 
plot_MFN_session <- ggplot() +
  geom_boxplot(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group), outlier.size =0.3)+
  geom_point(data = descriptive_statistics_MFN, aes(x = stimulation, y = MFN_0_100_FCz, colour = group), 
             position = position_dodge(width = 0.7), shape = 15, size = 1) +
  geom_errorbar(data = descriptive_statistics_MFN, aes(x = stimulation, ymax = MFN_0_100_FCz + ci, ymin = MFN_0_100_FCz - ci, colour = group),
                position = position_dodge(width = 0.7), width = 0, size = 0.5) +
  geom_line(data = descriptive_statistics_MFN, aes(x = stimulation, y = MFN_0_100_FCz, group = group, color = group), 
            position = position_dodge(width = 0.7), linetype = 3, size = 0.5) +
  scale_colour_manual(values = c("#b23f00", "#ff9b64"), name = "Group:") +
  scale_fill_manual(values = my_figure_colors, name = "Group:") +
  facet_wrap(~response_type + session, nrow = 1) +
  my_figure_theme + 
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])") 


# Save plot
 ggsave("./figures/figure_MFN_session.tiff", width = 20, height = 25, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN_session
```  
<br><br>

## LMM Analyses
***

MFN/ERN/CRN were modeled using a linear mixed-effects models (LMMs). <br><br>

**Fixed effects**

*Group (HC, OCD), stimulation (verum, sham), and response type (correct, incorrect)* were specified as fixed factors. Fixed effects were coded using effect coding (this equals sliding difference contrasts for two levels for factors with two levels or sum coding/2), such that the intercept reflects the grand mean across all conditions and differences in means between factor levels are tested. Fixed effects were not eliminated using model comparison techniques because they correspond to the original experimental design and a priori hypotheses. <br><br>


**Random effects**

Participants were specified as random factors. The random-effects structure for each model was determined based on the procedure proposed by Bates, Kliegl, et al. (2015). We started with the maximal random-effects structure  that was justified by the design, including random intercepts for participants, as well as random slopes for all main effects and interactions specified as fixed effects. If the model with the maximal random-effects structure would not converge, correlations of the random terms were set to zero. We performed a principal components analysis on the random-effects variance–covariance estimates to determine the number of components supported by the data and removed random effects explaining zero variance to prevent overparametrization (Matuschek et al., 2017).

```{r MFN-LMM-contrast-coding}

# Define contrasts (sliding difference contrasts)
contrasts(single_trial_data_clean$stimulation)   <- contr.sdif(2)
contrasts(single_trial_data_clean$group)         <- contr.sdif(2)
contrasts(single_trial_data_clean$response_type) <- contr.sdif(2)
contrasts(single_trial_data_clean$session)       <- contr.sdif(2)
contrasts(single_trial_data_clean$stimulus_type) <- contr.sdif(2)
contrasts(single_trial_data_clean$medication)    <- contr.sdif(2)


# Add contrasts as numerical covariates via model matrix* (specify all possible contasts for now)
model_matrix <- model.matrix(~ stimulation * group * response_type, single_trial_data_clean)


# Attach the model matrix (16 columns) to the dataframe
single_trial_data_clean[, (ncol(single_trial_data_clean) + 1):(ncol(single_trial_data_clean) + 8)] <- model_matrix


# Assign descriptive names to the contrasts
names(single_trial_data_clean)[(ncol(single_trial_data_clean) - 7):ncol(single_trial_data_clean)] <- c("Grand Mean", "verum_sham", "OCD_HC", "incorrect_correct", "verum_sham:OCD_HC", "verum_sham:incorrect_correct", "OCD_HC:incorrect_correct", "verum_sham:OCD_HC:incorrect_correct")


# *Note: For the random effects, we needed to enter the separate random effect terms in the models to enable
# double-bar notation (||). This allows fitting a model that sets correlations of the random terms to zero.
```
<br><br>

### LMM for MFN {.tabset}

#### Model

This is the overall model, including error and correct trials. This model will be reported before reporting the separate models for ERN and CRN, because it also shows the overall group effect and stimulation effect. 

```{r LMM-MFN, cache = knitr_cache_enabled}

# Run model with maximal random-effects structure
LMM_MFN <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * incorrect_correct +
  (1 + verum_sham + incorrect_correct + verum_sham:incorrect_correct | participant_id),
data = single_trial_data_clean,
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_MFN) # Model does converge
# isSingular(LMM_MFN) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_MFN)) # All terms explain variance (> 0.5%)


# Display results (fixed effects)
tab_model(LMM_MFN,
  dv.labels = "MFN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
There is a main effect of stimulation and response type and a trend for group. 
<br><br>

#### Assumption checks 

```{r LMM-MFN-assumptions, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# Check model assumptions
performance::check_model(LMM_MFN, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_MFN)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_MFN, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_MFN, effects = "random")
```

* **Assumption 1: Independence of Data Points / Absence of collinearity -> Is OK**
    + Are predictors not highly correlated?
    + Multicollinearity plot shows only low correlations 

* **Assumption 2: Normality of Residuals -> Is Not OK???** 
    + Are residuals approximately normally distributed?
    + Q-Q plot and density plot look not so great; Q-Q plot quite a bit off at the extremes 
    + It is debated whether this is problematic at all; and violation does not seem so bad, so maybe not worry about it? 

* **Assumption 3: Linearity -> Is OK** 
    + Is the dependent variable linearly related to the fixed factors, random factors, and covariates?
    + Plot of the residuals against the fitted values shows a random scatter pattern, no nonlinear or curvy pattern 

* **Assumption 4: Homogeneity of Residual Variance (Heteroscedasticity) -> Is OK???**
    + Have residuals constant variance across the range of the predicted values?
    + Plot of the residuals against the fitted values shows an even spread around the centered line; but written output says this is not ok

* **Assumption 5: Absence of Influential Data Points -> Is OK** 
    + Are there are no influential values? 
    + Cook's distance plot looks fine (for large N, Cook's distances should be below 1) and written output says there are no outliers 

* **Assumption 6: Normality of Random Effects -> Is OK**
    + Are random effects approximately normally distributed?
    + Written output says this is (mostly) ok 
<br><br>

### LMM for ERN / CRN {.tabset}

#### Model

```{r LMM-ERN-CRN, cache = knitr_cache_enabled}

# ERN
LMM_ERN <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_ERN) # Model does converge
# isSingular(LMM_ERN) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_ERN)) # All terms explain variance (> 0.5%)


tab_model(LMM_ERN,
  dv.labels = "ERN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN
LMM_CRN <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_CRN) # Model does converge
# isSingular(LMM_CRN) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_CRN)) # All terms explain variance


tab_model(LMM_CRN,
  dv.labels = "CRN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
There is a trend for a higher ERN in OCD compared to HC. There also is a trend for a higher CRN in OCD compared to HC. For CRN, there is an effect of stimulation, with smaller (i.e., less negative) CRN in the verum stimulation compared to the sham condition. There is a trend for a stimulation effect on ERN (which turns significant when using maximum likelihood instead of REML estimation). 
<br><br>

#### Assumption checks ERN model

```{r LMM-ERN-CRN-assumptions1, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# ERN check model assumptions
performance::check_model(LMM_ERN, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_ERN)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_ERN, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_ERN, effects = "random")
```

Notes for assumption check would be the same as written for the MFN model.
<br><br>

#### Assumption checks CRN model

```{r LMM-ERN-CRN-assumptions2, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# CRN check model assumptions
performance::check_model(LMM_CRN, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_CRN)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_CRN, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_CRN, effects = "random")
```

Notes for assumption check would be the same as written for the MFN model.
<br><br>

#### Check covariates

The purpose of including the covariates was to see how the effects change when controlling for the overall effect of the covariate. Thus, covariates were included only as fixed factor, not as random term. I first included the covariates as main effect only, not allowing any interactions with stimulation or group. However, inspecting the interactions as well might lead to new, important insights. These models including the interactions are presented below.
Note: The covariate number of errors refers to the actual number of errors committed by each participant, not the number included in the analyses. Continuous predictors were grand mean centered (number of errors, number of feedback faster) or within-subject mean-centered (baseline EEG). From Frömer et al. (2020; "When effort matters..."): "For each ERP, we regressed out the baseline activity at the same electrode sites (Alday et al., 2019). This approach accounts for variability prior to the effect of interest that can otherwise induce spurious effects due to noise or spill-over from previous stages of the trial. Although noise in the baseline is assumed to average to zero (across time points, as well as trials) when using traditional ERP-averaging approaches, this assumption does not necessarily hold for single-trial analyses, where a non-stationary baseline or unevenly distributed noise can easily lead to systematic biases in the subsequent time-series. To address these potential spurious effects, we follow recommendations to include the baseline as a nuisance regressor (Alday et al., 2019)."

```{r LMM-ERN-CRN-covariates, cache = knitr_cache_enabled}

# ERN check covariate baseline EEG
LMM_ERN_baseline_EEG <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * MFN_baseline_pre_200_0_FCz_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_baseline_EEG,
  dv.labels = "ERN [μV], covariate baseline EEG", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate baseline EEG
LMM_CRN_baseline_EEG <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * MFN_baseline_pre_200_0_FCz_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_baseline_EEG,
  dv.labels = "CRN [μV], covariate baseline EEG", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate session
LMM_ERN_session <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * session  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_session,
  dv.labels = "ERN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate session
LMM_CRN_session <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * session  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_session,
  dv.labels = "CRN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of errors (predictor was z standardized)
LMM_ERN_number_errors <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_number_errors,
  dv.labels = "ERN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)

 
# CRN check covariate number of errors (predictor was z standardized)
LMM_CRN_number_errors <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_number_errors,
  dv.labels = "CRN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of feedback faster (predictor was z standardized)
LMM_ERN_number_feedback_faster <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_number_feedback_faster,
  dv.labels = "ERN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate number of feedback faster (predictor was z standardized)
LMM_CRN_number_feedback_faster <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_number_feedback_faster,
  dv.labels = "CRN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate stimulus type
LMM_ERN_stimulus_type <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * stimulus_type  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_stimulus_type,
  dv.labels = "ERN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate stimulus_type
LMM_CRN_stimulus_type <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * stimulus_type  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_stimulus_type,
  dv.labels = "CRN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate medication
LMM_ERN_medication <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * medication  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_medication,
  dv.labels = "ERN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate medication
LMM_CRN_medication <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * medication  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_medication,
  dv.labels = "CRN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only unmedicated participants
LMM_ERN_unmedicated <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC +  
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_unmedicated,
  dv.labels = "ERN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only unmedicated participants
LMM_CRN_unmedicated <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_unmedicated,
  dv.labels = "CRN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only unmedicated patients
LMM_ERN_unmedicated_OCD <- lmer(MFN_0_100_FCz ~ verum_sham  +  
  (1 | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no" & single_trial_data_clean$group == "OCD",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_unmedicated_OCD,
  dv.labels = "ERN [μV], only unmedicated patients", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only unmedicated patients
LMM_CRN_unmedicated_OCD <- lmer(MFN_0_100_FCz ~ verum_sham  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$medication == "no" & single_trial_data_clean$group == "OCD",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_unmedicated_OCD,
  dv.labels = "CRN [μV], only unmedicated patients", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>

**Covariates**
<br><br>

* **ERN group difference**: Remains a trend when including the covariate session, number of feedback faster, or stimulus type in the model. Turns non-significant when including the variable baseline EEG, number of errors or medication in the model. 

* **CRN group difference**: Remains a trend when including the covariate baseline EEG, session, number of feedback faster, or stimulus type in the model. Turns non-significant when including the variable number of errors or medication in the model.

* **ERN stimulation effect**: Remains a trend when including the covariate baseline EEG, session, or medication in the model. Turns non-significant when including the variable number of errors, number of feedback faster, or stimulus type in the model. 

* **CRN stimulation effect**: Remains significant when including the covariate baseline EEG, session, number of errors (almost sign.),  stimulus type, or medication in the model. Turns to a trend when including the variable number of feedback faster in the model (but only when allowing interactions with the covariate, not when only allowing its main effect). 
<br><br>

**Subgroup analyses**

When including only unmedicated participants, there is no ERN group difference anymore, no CRN group trend anymore and no CRN stimulation effect anymore (possibly due to reduced power). When including only unmedicated participants, there is no stimulation effect on ERN or CRN anymore.
<br><br>

### LMM for ERN / CRN (nested) {.tabset}

#### Model

```{r LMM-ERN-CRN-per-group, cache = knitr_cache_enabled}

# ERN
LMM_ERN_group <- lmer(MFN_0_100_FCz ~ group/stimulation  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


tab_model(LMM_ERN_group,
  dv.labels = "ERN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN
LMM_CRN_group <- lmer(MFN_0_100_FCz ~ group/stimulation  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


tab_model(LMM_CRN_group,
  dv.labels = "CRN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
For the separate groups, there is no significant effect of stimulation on ERN. According to the plots above it seemed that at least in the HC group, there is a smaller (i.e., less negative) ERN in the verum than in the sham condition. But this is not significant in the LMM.
For the CRN, there was a main effect of stimulation (see above). When testing this effect separately in the groups, a stimulation effect on CRN is evident for the OCD but not for the HC group. The higher order interaction group * stimulation was not significant (p = .114).
<br><br>

#### Assumption checks 

Is same as in non-nested models (tab LMM separately for ERN / CRN)
<br><br>

#### Check covariates

```{r LMM-ERN-CRN-per-group-covariates, cache = knitr_cache_enabled}


# ERN check covariate baseline EEG
LMM_ERN_group_baseline_EEG <- lmer(MFN_0_100_FCz ~ group/stimulation * MFN_baseline_pre_200_0_FCz_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_baseline_EEG,
  dv.labels = "ERN [μV], covariate baseline EEG", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate baseline EEG
LMM_CRN_group_baseline_EEG <- lmer(MFN_0_100_FCz ~ group/stimulation * MFN_baseline_pre_200_0_FCz_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_baseline_EEG,
  dv.labels = "CRN [μV], covariate baseline EEG", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)



# ERN check covariate session
LMM_ERN_group_session <- lmer(MFN_0_100_FCz ~ group/stimulation * session  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_session,
  dv.labels = "ERN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate session
LMM_CRN_group_session <- lmer(MFN_0_100_FCz ~ group/stimulation * session  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_session,
  dv.labels = "CRN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of errors (predictor was z standardized)
LMM_ERN_group_number_errors <- lmer(MFN_0_100_FCz ~ group/stimulation * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_number_errors,
  dv.labels = "ERN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate number of errors (predictor was z standardized)
LMM_CRN_group_number_errors <- lmer(MFN_0_100_FCz ~ group/stimulation * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_number_errors,
  dv.labels = "CRN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of feedback faster (predictor was z standardized)
LMM_ERN_group_number_feedback_faster <- lmer(MFN_0_100_FCz ~ group/stimulation * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_number_feedback_faster,
  dv.labels = "ERN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate number of feedback faster (predictor was z standardized)
LMM_CRN_group_number_feedback_faster <- lmer(MFN_0_100_FCz ~ group/stimulation * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_number_feedback_faster,
  dv.labels = "CRN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate stimulus type
LMM_ERN_group_stimulus_type <- lmer(MFN_0_100_FCz ~ group/stimulation * stimulus_type  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_stimulus_type,
  dv.labels = "ERN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate stimulus_type
LMM_CRN_group_stimulus_type <- lmer(MFN_0_100_FCz ~ group/stimulation * stimulus_type  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_stimulus_type,
  dv.labels = "CRN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate medication
LMM_ERN_group_medication <- lmer(MFN_0_100_FCz ~ group/stimulation * medication  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_medication,
  dv.labels = "ERN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate medication
LMM_CRN_group_medication <- lmer(MFN_0_100_FCz ~ group/stimulation * medication  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_medication,
  dv.labels = "CRN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only unmedicated participants
LMM_ERN_group_unmedicated <- lmer(MFN_0_100_FCz ~ group/stimulation +  
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_unmedicated,
  dv.labels = "ERN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only unmedicated participants
LMM_CRN_group_unmedicated <- lmer(MFN_0_100_FCz ~ group/stimulation + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_unmedicated,
  dv.labels = "CRN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
**Covariates**

For further infos, see notes in section non-nested ERN-CRN models.
<br><br>

* **ERN group difference**: See notes in section non-nested ERN-CRN models.

* **CRN group difference**: See notes in section non-nested ERN-CRN models.

* **ERN stimulation effect in HC/OCD**: For HC and OCD remains non-significant in all models.

* **CRN stimulation effect in HC/OCD**: For HC remains non-significant in all models. For OCD remains significant in all models. 
<br><br>

**Subgroup analyses**

When including only unmedicated patients, there is no ERN group difference anymore, no CRN group trend anymore and no CRN stimulation effect in OCD anymore (possibly due to reduced power). 
<br><br>

### LMM for Pe {.tabset}

#### Model

```{r LMM-Pe, cache = knitr_cache_enabled}

# Pe
LMM_Pe <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_Pe) # Model does converge
# isSingular(LMM_Pe) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_Pe)) # All terms explain variance (> 0.5%)


tab_model(LMM_Pe,
  dv.labels = "Pe [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
There is no group difference but a significant stimulation effect on Pe, with a higher Pe for verum stimulation (this is in line with Reinhart & Woodman, 2014). There is no interaction group * stimulation. 
<br><br>

#### Assumption checks

```{r LMM-Pe-assumptions, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# Pe check model assumptions
performance::check_model(LMM_Pe, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_Pe)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_Pe, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_Pe, effects = "random")
```

Notes for assumption check would be the same as written for the MFN model.
<br><br>

#### Check covariates

```{r LMM-Pe-covariates, cache = knitr_cache_enabled}

# Pe check covariate baseline EEG
LMM_Pe_baseline_EEG <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC * Pe_baseline_pre_200_0_Pz_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_baseline_EEG,
  dv.labels = "Pe [μV], covariate baseline EEG", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate session
LMM_Pe_session <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC * session  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_session,
  dv.labels = "Pe [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate number of errors (predictor was z standardized)
LMM_Pe_number_errors <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_number_errors,
  dv.labels = "Pe [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)

 
# Pe check covariate number of feedback faster (predictor was z standardized)
LMM_Pe_number_feedback_faster <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_number_feedback_faster,
  dv.labels = "Pe [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate stimulus type
LMM_Pe_stimulus_type <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC * stimulus_type  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_stimulus_type,
  dv.labels = "Pe [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate medication
LMM_Pe_medication <- lmer(Pe_200_400_Pz ~ verum_sham * OCD_HC * medication  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_medication,
  dv.labels = "Pe [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe include only unmedicated participants
LMM_Pe_unmedicated <- lmer(Pe_200_400_Pz ~ verum_sham  +  
  (1 +  verum_sham| participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_unmedicated,
  dv.labels = "Pe [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe include only unmedicated patients
LMM_Pe_unmedicated_OCD <- lmer(Pe_200_400_Pz ~ verum_sham  +  
  (1 | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no" & single_trial_data_clean$group == "OCD",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_unmedicated_OCD,
  dv.labels = "Pe [μV], only unmedicated patients", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
**Covariates**

For further infos, see notes in section non-nested ERN-CRN models.
<br><br>

* **Pe group difference**: Remains non-significant in all models. 

* **Pe stimulation effect**: Remains significant when including the covariate session, number of errors, number of feedback faster. Turns trend when including the covariate baseline EEG. Turns non-significant when including the variable stimulus type or medication in the model. 

* **Subgroup analysis**: When including only unmedicated participants or unmedicated patients, the stimulation effect on Pe remains significant. 
<br><br>


### LMM for Pe (nested) {.tabset}

#### Model

```{r LMM-Pe-per-group, cache = knitr_cache_enabled}

# Pe
LMM_Pe_group <- lmer(Pe_200_400_Pz ~ group/stimulation + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_Pe_group) # Model does converge
# isSingular(LMM_Pe_group) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_Pe_group)) # All terms explain variance (> 0.5%)


tab_model(LMM_Pe_group,
  dv.labels = "Pe [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
For the Pe, there was a main effect of stimulation (see above). When testing this effect separately in the groups, a stimulation effect on Pe is evident for the OCD but not for the HC group. The higher order interaction group * stimulation was not significant.
<br><br>


#### Assumption checks 

Is same as in non-nested model (tab LMM Pe)
<br><br>

#### Check covariates

```{r LMM-Pe-per-group-covariates, cache = knitr_cache_enabled}

# Pe check covariate baseline EEG
LMM_Pe_group_baseline_EEG <- lmer(Pe_200_400_Pz ~ group/stimulation * Pe_baseline_pre_200_0_Pz_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_group_baseline_EEG,
  dv.labels = "Pe [μV], covariate baseline EEG", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate session
LMM_Pe_group_session <- lmer(Pe_200_400_Pz ~ group/stimulation * session  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_group_session,
  dv.labels = "Pe [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate number of errors (predictor was z standardized)
LMM_Pe_group_number_errors <- lmer(Pe_200_400_Pz ~ group/stimulation * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_group_number_errors,
  dv.labels = "Pe [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)

 
# Pe check covariate number of feedback faster (predictor was z standardized)
LMM_Pe_group_number_feedback_faster <- lmer(Pe_200_400_Pz ~ group/stimulation * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_group_number_feedback_faster,
  dv.labels = "Pe [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate stimulus type
LMM_Pe_group_stimulus_type <- lmer(Pe_200_400_Pz ~ group/stimulation * stimulus_type  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_group_stimulus_type,
  dv.labels = "Pe [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# Pe check covariate medication
LMM_Pe_group_medication <- lmer(Pe_200_400_Pz ~ group/stimulation * medication  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_Pe_group_medication,
  dv.labels = "Pe [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
**Covariates**

For further infos, see notes in section non-nested ERN-CRN models.
<br><br>

* **Pe group difference**: See notes in section non-nested model.

* **Pe stimulation effect in HC/OCD**: For HC remains non-significant in all models. For OCD remains significant in all models, except for the model including the variable baseline EEG or stimulus type. 
<br><br>

## ANOVAs {.tabset}
***

### ANOVAs

To facilitate comparison with previously reported results obtained using a similar task and aggregation-based analyses (Rainhart & Woodman 2014), MFN/ERN/CRN/Diff incorrect - correct (as mean amplitude and mean area) were additionally analyzed with repeated-measures analyses of variance (ANOVAs) including the within-participant factors stimulation (verum, sham), group (OCD, HC), and (only for MRN) response type (correct, incorrect). No  Greenhouse–Geisser correction was applied, as no factor had more than two levels. As can be seen below, the MFN, ERN, and CRN ANOVAs yielded the same results as obtained with mixed-effects modeling with respect to all effects (trend for ERN and CRN group difference and stimulation effect on ERN, significant stimulation effect on CRN). When using the ERN quantification as in Reinhart & Woodman (-50 to 150 as difference incorrect - correct mean area) or the difference incorrect - correct mean amplitude as dependent variable, there is no group or stimulation effect. 

```{r ANOVAs}

# Due to the afex package, contrasts are automatically set to effect-coding (contr.sum). Afex package 
# also checks sphericity assumptions and automatically corrects for any violations if necessary.


# ANOVA overall
anova_MFN <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN", 
  data   = df_aggregated_per_subject_MFN,
  within = c("stimulation", "response_type"),
  between= c("group"),
  observed = c("group")
)


# ANOVA ERN
anova_ERN <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN", 
  data   = df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$response_type == "incorrect",],
  within = c("stimulation"),
  between= c("group"),
  observed = c("group")
)



# ANOVA CRN
anova_CRN <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN", 
  data   = df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$response_type == "correct",],
  within = c("stimulation"),
  between= c("group"),
  observed = c("group")
)


# ANOVA difference incorrect - correct mean amplitude (0 to 100 ms at FCz)
anova_incorrect_minus_correct <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN_incorrect_minus_correct", 
  data   = df_aggregated_per_subject_MFN_diff,
  within = c("stimulation"),
  between= c("group"),
  observed = c("group")
)


# ANOVA difference incorrect - correct mean area (-50 to 150 ms at FCz) as in Reinahrt & Woodman (2014)
anova_incorrect_minus_correct_area <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN_incorrect_minus_correct_area", 
  data   = df_aggregated_per_subject_MFN_diff,
  within = c("stimulation"),
  between= c("group"),
  observed = c("group")
)


# Display ANOVA results
my_table_template(nice(anova_MFN, MSE = FALSE), caption = "MFN")
my_table_template(nice(anova_ERN, MSE = FALSE), caption = "ERN")
my_table_template(nice(anova_CRN, MSE = FALSE), caption = "CRN")
my_table_template(nice(anova_incorrect_minus_correct, MSE = FALSE), caption = "Difference incorrect - correct mean amplitude (0 to 100 ms at FCz)")
my_table_template(nice(anova_incorrect_minus_correct_area, MSE = FALSE), caption = "Difference incorrect - correct mean area (-50 to 150 ms at FCz) as described by Reinhart & Woodman (2014)")
```
<br><br>

### Pairwise comparisons

As no significant main effect with > 2 levels or interaction effect was present, no post hoc pairwise comparisons would need to be conducted. However, the stimulation effect on ERN in the separate groups may be seen as pre-planned contrast that we want to test. For these effects, I calculated pairwise comparisons using the emmeans package with Holm–Bonferroni *p* value adjustments. There is still no stimulation effect on ERN in the two groups (but not too far away either). The effect on CRN is present in the OCD group. In the sham condition, the CRN is higher (more negative) in the OCD group; in the verum condition there is no significant group difference anymore. Quantifying the ERN as the difference incorrect - correct mean area (-50 to 150 ms at FCz) as described by Reinhart & Woodman (2014), there is a trend for a stimulation effect in the HC group. 

```{r ANOVAs-pairwise-tests}

# Use multivariate model for all follow-up tests to adequately control for violations of sphericity
afex_options(emmeans_model = "multivariate")


# Pairwise t tests
pairwise_ERN    <- summary(pairs(emmeans(anova_ERN, "stimulation", by = "group"), adjust = "holm"))
pairwise_CRN_1  <- summary(pairs(emmeans(anova_CRN, "stimulation", by = "group"), adjust = "holm"))
pairwise_CRN_2  <- summary(pairs(emmeans(anova_CRN, "group", by = "stimulation"), adjust = "holm"))
pairwise_incorrect_minus_correct      <- summary(pairs(emmeans(anova_incorrect_minus_correct,      "stimulation", by = "group"), adjust = "holm"))
pairwise_incorrect_minus_correct_area <- summary(pairs(emmeans(anova_incorrect_minus_correct_area, "stimulation", by = "group"), adjust = "holm"))



# Add Cohen's dz (CIs for d could be added if needed, as it can be returned by the "t_to_d" function)
pairwise_ERN$cohens_dz   <- round(t_to_d(pairwise_ERN$t.ratio,   pairwise_ERN$df,   paired = TRUE)[1], digits = 2)
pairwise_CRN_1$cohens_dz <- round(t_to_d(pairwise_CRN_1$t.ratio, pairwise_CRN_1$df, paired = TRUE)[1], digits = 2)
pairwise_CRN_2$cohens_dz <- round(t_to_d(pairwise_CRN_2$t.ratio, pairwise_CRN_2$df, paired = TRUE)[1], digits = 2)
pairwise_incorrect_minus_correct$cohens_dz      <- round(t_to_d(pairwise_incorrect_minus_correct$t.ratio,      pairwise_incorrect_minus_correct$df,     paired = TRUE)[1], digits = 2)
pairwise_incorrect_minus_correct_area$cohens_dz <- round(t_to_d(pairwise_incorrect_minus_correct_area$t.ratio, pairwise_incorrect_minus_correct_area$df, paired = TRUE)[1], digits = 2)

# Display results 
my_table_template(pairwise_ERN, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "ERN: Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 


my_table_template(pairwise_CRN_1, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "CRN: Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 


my_table_template(pairwise_CRN_2, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "CRN: Group Effect Within Stimulation",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 

my_table_template(pairwise_incorrect_minus_correct, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "Difference Incorrect Minus Correct Mean Amplitude (0 to 100 ms at FCz): Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 

my_table_template(pairwise_incorrect_minus_correct_area, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "Difference Incorrect Minus Correct Mean Area (-50 to 150 ms at FCz): Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 
```
### Simple t tests

Same results as with pairwise comparisons via emmeans and p value adjustment: There is still no stimulation effect on ERN in the two groups. The effect on CRN is present in the OCD group. Note that here the p values are not adjusted for multiple comparisons yet.

```{r t-tests}

# Stimulation effect on ERN in OCD -> n.s.
ERN_OCD <- t.test(MFN ~ stimulation,
                  data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "OCD" & 
                                                     df_aggregated_per_subject_MFN$response_type == "incorrect",],
                  paired=TRUE)


# Stimulation effect on ERN in HC -> n.s.
ERN_HC <- t.test(MFN ~ stimulation,
                 data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "HC" & 
                                                    df_aggregated_per_subject_MFN$response_type == "incorrect",],
                 paired=TRUE)


# Stimulation effect on CRN in OCD -> sign. 
CRN_OCD <- t.test(MFN ~ stimulation,
                  data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "OCD" & 
                                                     df_aggregated_per_subject_MFN$response_type == "correct",],
                  paired=TRUE)


# Stimulation effect on CRN in HC -> n.s. 
CRN_HC <- t.test(MFN ~ stimulation,
                 data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "HC" & 
                                                    df_aggregated_per_subject_MFN$response_type == "correct",],
                 paired=TRUE)


# Mke nice table for display
library(broom)
library(purrr)

tab <- map_df(list(ERN_OCD, ERN_HC,  CRN_OCD, CRN_HC), tidy)
contrast = c("OCD ERN: sham-verum", "HC ERN: sham-verum", "OCD CRN: sham-verum", "HC CRN: sham-verum")
my_table_template(cbind(contrast, tab[c("estimate", "statistic", "p.value")]))
```
<br><br>

### Assumption checks

```{r ANOVAs-assumptions, fig.height = 6}

# Get residuals
residuals_anova_MFN      <- as.data.frame(anova_MFN$lm$residuals)
residuals_anova_ERN      <- as.data.frame(anova_ERN$lm$residuals)
residuals_anova_CRN      <- as.data.frame(anova_CRN$lm$residuals)


# Plot residuals
hist_residuals_anova_MFN <- ggplot(gather(residuals_anova_MFN, cols, value), aes(x = value)) + 
  geom_histogram(color = my_figure_colors[2], fill = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "Histogram Residuals MFN") + my_figure_theme

qqplot_residuals_anova_MFN <- ggplot(gather(residuals_anova_MFN, cols, value), aes(sample = value)) + 
  stat_qq(color = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "QQ-Plot Residuals MFN") + my_figure_theme

hist_residuals_anova_ERN <- ggplot(gather(residuals_anova_ERN, cols, value), aes(x = value)) + 
  geom_histogram(color = my_figure_colors[2], fill = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "Histogram Residuals ERN") + my_figure_theme

qqplot_residuals_anova_ERN <- ggplot(gather(residuals_anova_ERN, cols, value), aes(sample = value)) + 
  stat_qq(color = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "QQ-Plot Residuals ERN") + my_figure_theme

hist_residuals_anova_CRN <- ggplot(gather(residuals_anova_CRN, cols, value), aes(x = value)) + 
  geom_histogram(color = my_figure_colors[2], fill = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "Histogram Residuals CRN") + my_figure_theme

qqplot_residuals_anova_CRN <- ggplot(gather(residuals_anova_CRN, cols, value), aes(sample = value)) + 
  stat_qq(color = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "QQ-Plot Residuals CRN") + my_figure_theme

ggdraw() +
  draw_plot(hist_residuals_anova_MFN,       x =  0,   y = .6, width = .5, height = .4) +
  draw_plot(qqplot_residuals_anova_MFN,     x =  .5,  y = .6, width = .5, height = .4) +
  draw_plot(hist_residuals_anova_ERN,       x =  0,   y = .3, width = .5, height = .3) +
  draw_plot(qqplot_residuals_anova_ERN,     x =  .5,  y = .3, width = .5, height = .3) +
  draw_plot(hist_residuals_anova_CRN,       x =  0,   y = 0,  width = .5, height = .3) +
  draw_plot(qqplot_residuals_anova_CRN,     x =  .5,  y = 0,  width = .5, height = .3) 


# Test normality of residuals
print("# ANOVA MFN: Normality of Residuals with Shapiro Wilk Test")
do.call(rbind, lapply(residuals_anova_MFN[,], function(x) shapiro.test(x)["p.value"]))

print("# ANOVA ERN: Check Normality of Residuals with Shapiro Wilk Test")
do.call(rbind, lapply(residuals_anova_ERN[,], function(x) shapiro.test(x)["p.value"]))

print("# ANOVA CRN: Check Normality of Residuals with Shapiro Wilk Test")
do.call(rbind, lapply(residuals_anova_CRN[,], function(x) shapiro.test(x)["p.value"]))
```

* **Assumption #1: Dependent variable interval or ratio variable -> Is OK**

* **Assumption #2: Balanced design** (each subject has to have a value in each condition) **-> Is OK**

* **Assumption #3: No dependency in the scores between participants** (dependency can exist only across scores for individuals) **-> Is OK**

* **Assumption #4: Residuals** of the dependent variable in each level of the within-subjects factor are approximately **normally distributed -> Is OK** (see above; for incorrect verum condition only small deviation)

* **Assumption #5: Sphericity** (only relevant for withlin-subject factors with > 2 levels) (afex package automatically corrects (Greenhouse Geisser) for any violations if necessary) **-> Is OK**

<br><br>

