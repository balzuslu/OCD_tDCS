---
title: "ERP Analysis"
output: 
  html_document

---

<!-- Set general settings -->

```{r setup, include = FALSE}

# Set general settings for markdown file
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = "",
  results = "hold"
)


# Clear environment
rm(list = ls())


# Enable/disable caching of time-consuming code chunks
knitr_cache_enabled = TRUE


# Load packages
library(dplyr)      # for data manipulation
library(knitr)      # for integrating computing and reporting in markdown
library(kableExtra) # for customizing appearance of tables
library(ggplot2)    # for plotting
library(cowplot)    # for arranging plots
library(e1071)      # for functions skewness and kurtosis
library(MASS)       # for boxcox function and contrast definition
library(lme4)       # for (G)LMMs
library(lmerTest)   # for LMM p values (Satterthwaite's method for approximating dfs for the t and F tests)
library(sjPlot)     # for tab_model function to display (G)LMM results
library(performance)# for check of model various assumptions
library(influence.ME) # to calculate Cook's distance
library(emmeans)    # for pairwise comparisons
library(afex)       # for ANOVAs (convenience functions, e.g. for nice display)
library(effectsize) # for effect sizes (t_to_d function)
library(tidyr)      # for reshape function
library(readr)      # for raincloud plots
library(lavaan)     # for raincloud plots
library(splithalf)  # for permutation-based split-half reliability


# Load functions
source("./functions/summarySEwithinO.R")  # Function provided by R-cookbook: http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/
source("./functions/my_table_template.R") # Function to create table template
source("./functions/R_rainclouds.R")      # Function to create raincloud plots


# Turn off scientific notation
options(scipen = 999)


# Set figure theme and colors
my_figure_theme <- theme_classic(base_size = 11) +
  theme(legend.position = "bottom", 
        strip.background = element_rect(fill="grey95", linetype = "blank"),
        axis.ticks.x = element_blank(), 
        plot.title = element_text(hjust = 0.5)) 
# instad of theme_classic: + theme_apa(base_size = 11)

my_figure_colors <- c("#8ea6b4", "#465369")
```

## Data Cleaning
***

```{r load-and-clean-data, cache = knitr_cache_enabled}

# Load data
load(file = "./data/Single_Trial_Data.rda")


# Exclude missing responses, RT outliers and trials with ERP artifacts
single_trial_data_clean <- single_trial_data %>%
  dplyr::filter(
      response_type != "miss" &
      rt_invalid  == FALSE &
      !is.nan(MFN_0_100_FCz)
  ) # (54998 of 55680 trials left)


# Add column for number of errors (needed as covariate later) - this variable contains total number of errors, not only those entering analysis (preferred according to JK)
single_trial_data_clean <- single_trial_data %>% 
  dplyr::group_by(participant_id, session) %>% 
  dplyr::summarize(number_errors = sum(response_type == "incorrect")) %>%
  dplyr::ungroup(.) %>%
  dplyr::left_join(single_trial_data_clean, ., by = c("participant_id", "session"))
# Standardize this variable
single_trial_data_clean$number_errors_standardized <- scale(single_trial_data_clean$number_errors, center = TRUE, scale = TRUE)


# Add column for number of speeding (needed as covariate later) 
load(file = "./data/Feedback_Infos.rda")
single_trial_data_clean <- feedback_infos[feedback_infos$block != 6,] %>% 
  dplyr::group_by(participant_id, session, feedback) %>%
  dplyr::count(feedback, .drop = FALSE) %>%
  dplyr::filter(feedback == " schneller") %>%
  dplyr::rename(number_feedback_faster = n) %>%
  dplyr::ungroup(.) %>%  
  dplyr::select(-feedback) %>%
  dplyr::left_join(single_trial_data_clean, ., by = c("participant_id", "session"))
# Standardize this variable
single_trial_data_clean$number_feedback_faster_standardized <- scale(single_trial_data_clean$number_feedback_faster, center = TRUE, scale = TRUE)


# Add column for medication (needed as covariate later) 
single_trial_data_clean <- single_trial_data_clean %>% 
  dplyr::mutate(medication = as.factor(ifelse(participant_id == "P_02" | participant_id == "P_04" | participant_id == "P_05" |
                                              participant_id == "P_06" | participant_id == "P_08" | participant_id == "P_10" |
                                              participant_id == "P_15" | participant_id == "P_16" | participant_id == "P_18" |
                                              participant_id == "P_22" | participant_id == "P_25" | participant_id == "P_26" |
                                              participant_id == "P_28" | participant_id == "P_30", "yes", "no")))


# Calculate aggregated data per subject for boxplots, ANOVAs, t tests, and outlier detection
df_aggregated_per_subject_MFN <- single_trial_data_clean %>%
  dplyr::group_by(participant_id, group, response_type, stimulation, session) %>%
  dplyr::summarize(
    MFN = mean(MFN_0_100_FCz, na.rm = TRUE)
   ) 


# Make categorical variables factors
single_trial_data_clean$participant_id      <- as.factor(single_trial_data_clean$participant_id) 
single_trial_data_clean$group               <- as.factor(single_trial_data_clean$group)
single_trial_data_clean$session             <- as.factor(single_trial_data_clean$session)
single_trial_data_clean$stimulation         <- as.factor(single_trial_data_clean$stimulation)
single_trial_data_clean$stimulus_type       <- as.factor(single_trial_data_clean$stimulus_type)
single_trial_data_clean$response_type       <- as.factor(single_trial_data_clean$response_type)
```

Trials were excluded from all analyses if RT was shorter than 100 ms or longer than 800 ms or if the response in a trial was missing. We further discarded trials containing artifacts in the EEG, i.e., a voltage difference exceeding 50 μV between two consecutive sampling points or 200 μV within an epoch. 

```{r excluded-trials}

# Calculate percentage of excluded trials per participant
excluded_trials_per_participant <- single_trial_data %>%
  dplyr::group_by(group, participant_id, session) %>%
  dplyr::summarize(
    invalid_rt   = sum(!is.na(rt_invalid) & rt_invalid != FALSE) / length(participant_id) * 100,
    misses       = sum(response_type == "miss") / length(participant_id) * 100,
    EEG_artifact = sum(is.nan(MFN_0_100_FCz)) / length(participant_id) * 100
   ) %>%
  dplyr::group_by(group) %>%
  # Calculate M and SD of the variables
  dplyr::summarize(across(-c(participant_id, session), list(mean,sd,min,max)))


# Display percentage of excluded trials per participant
my_table_template(excluded_trials_per_participant,
  caption = "Excluded Trials (M and SD in %) per Participant", 
  col_names = c("Group", "M", "SD", "min", "max", "M", "SD", "min", "max", "M", "SD", "min", "max"),
  header_above_config = c(" " = 1, "RT < 100 / > 800 ms" = 4, "Misses" = 4, "EEG artifact" = 4)
)


# Calculate percentage of excluded trials in total
excluded_trials_in_total <- single_trial_data %>%
  dplyr::summarize(
    invalid_rt   = sum(!is.na(rt_invalid) & rt_invalid != FALSE) / nrow(single_trial_data) * 100,
    misses       = sum(response_type == "miss") / nrow(single_trial_data) * 100,
    EEG_artifact = sum(is.nan(MFN_0_100_FCz)) / nrow(single_trial_data) * 100
   )


# Display percentage of excluded trials in total
my_table_template(excluded_trials_in_total,
  caption = "Excluded Trials (in %) in Total") 


# Detect ERP outliers (ERP deviates more than 2/3 SD below/above group mean per condition)
library(plyr)
ERP_outliers <- df_aggregated_per_subject_MFN %>% 
  dplyr::group_by(participant_id, stimulation, group, response_type) %>%
  plyr::mutate(outlier_2_sd_above = ifelse(abs(MFN)>mean(MFN)+2*sd(MFN), TRUE, FALSE),
               outlier_3_sd_above = ifelse(abs(MFN)>mean(MFN)+3*sd(MFN), TRUE, FALSE),
               outlier_2_sd_below = ifelse(abs(MFN)<mean(MFN)-2*sd(MFN), TRUE, FALSE),
               outlier_3_sd_below = ifelse(abs(MFN)<mean(MFN)-3*sd(MFN), TRUE, FALSE)) %>%
  dplyr::filter(outlier_2_sd_above == TRUE | outlier_2_sd_below == TRUE)


# Display ERP outliers
my_table_template(ERP_outliers, caption = "ERP outliers (> 2/3 SD below/above group mean per condition (response type x stimulation))")
```
There is one participant (P_28_T2) whose ERN deviates > 3 SD from the group mean per condition (response type x stimulation). This participant is also quite prominent in the raincloud plot (see below). There are a few participants whose ERN deviates > 2 SD. I think we should not exclude participants based on this criterion? Being an outlier in ERP magnitude is also no exclusion criterion specified in the preregistration. 
<br><br>

## Data Inspection {.tabset}
***

### Distribution

```{r inspect-distribution, cache = knitr_cache_enabled}

# Plot distribution MFN
hist_MFN <- ggplot(single_trial_data_clean, aes(x = MFN_0_100_FCz)) +
  geom_histogram(aes(y = ..density..), color="gray33", fill = "#8ea6b4", size = 1) +
  stat_function(fun = dnorm, args=list(mean = mean(single_trial_data_clean$MFN_0_100_FCz, na.rm = TRUE), 
                                     sd = sd(single_trial_data_clean$MFN_0_100_FCz, na.rm = TRUE)), color = "black", size = 0.5) +
  geom_vline(aes(xintercept = mean(MFN_0_100_FCz, na.rm = TRUE)), color = "black", linetype = "dashed", size = 1) +
  labs (title = "Histogram MFN", x = "MFN", y = "Density") + 
  my_figure_theme 

qqplot_MFN <- ggplot(single_trial_data_clean, aes(sample = MFN_0_100_FCz)) +
  stat_qq(color = "#8ea6b4") +
  stat_qq_line() +
  labs (title = "Q-Q-Plot MFN", x = "Theoretical Quantiles", y = "Sample Quantiles") + 
  my_figure_theme


# Plot distribution ERN
hist_ERN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",], aes(x = MFN_0_100_FCz)) +
  geom_histogram(aes(y = ..density..), color="gray33", fill = "#8ea6b4", size = 1) +
  stat_function(fun = dnorm, args=list(mean = mean(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz, na.rm = TRUE), 
                                     sd = sd(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz, na.rm = TRUE)), color = "black", size = 0.5) +
  geom_vline(aes(xintercept = mean(MFN_0_100_FCz, na.rm = TRUE)), color = "black", linetype = "dashed", size = 1) +
  labs (title = "Histogram ERN", x = "ERN", y = "Density") + 
  my_figure_theme

qqplot_ERN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",], aes(sample = MFN_0_100_FCz)) +
  stat_qq(color = "#8ea6b4") +
  stat_qq_line() +
  labs (title = "Q-Q-Plot ERN", x = "Theoretical Quantiles", y = "Sample Quantiles") + 
  my_figure_theme


# Plot distribution CRN
hist_CRN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "correct",], aes(x = MFN_0_100_FCz)) +
  geom_histogram(aes(y = ..density..), color="gray33", fill = "#8ea6b4", size = 1) +
  stat_function(fun = dnorm, args=list(mean = mean(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz, na.rm = TRUE), 
                                     sd = sd(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz, na.rm = TRUE)), color = "black", size = 0.5) +
  geom_vline(aes(xintercept = mean(MFN_0_100_FCz, na.rm = TRUE)), color = "black", linetype = "dashed", size = 1) +
  labs (title = "Histogram CRN", x = "CRN", y = "Density") + 
  my_figure_theme

qqplot_CRN <- ggplot(single_trial_data_clean[single_trial_data_clean$response_type == "correct",], aes(sample = MFN_0_100_FCz)) +
  stat_qq(color = "#8ea6b4") +
  stat_qq_line() +
  labs (title = "Q-Q-Plot CRN", x = "Theoretical Quantiles", y = "Sample Quantiles") + 
  my_figure_theme

ggdraw() +
  draw_plot(hist_MFN,       x =  0,   y = .66,   width = .5, height = .33) +
  draw_plot(qqplot_MFN,     x =  .5,  y = .66,   width = .5, height = .33) +
  draw_plot(hist_ERN,       x =  0,   y = .33,   width = .5, height = .33) +
  draw_plot(qqplot_ERN,     x =  .5,  y = .33,   width = .5, height = .33) +
  draw_plot(hist_CRN,       x =  0,   y = 0,     width = .5, height = .33) +
  draw_plot(qqplot_CRN,     x =  .5,  y = 0,     width = .5, height = .33) 
```
<br><br>

### ERN/CRN per participant 

```{r plot-RT-per-subject-and-response-type, fig.width = 12, fig.height = 20, cache = knitr_cache_enabled}

MFN_per_participant <- ggplot(single_trial_data_clean, aes(x = response_type, y = MFN_0_100_FCz, group = response_type)) + 
  geom_point(aes(fill = response_type), color = "black", shape = 21, position = "jitter") + 
  ggtitle("MFN per participant") + 
  my_figure_theme + 
  facet_wrap(~ participant_id + stimulation, ncol = 10) +
  scale_fill_manual(values = my_figure_colors) 
MFN_per_participant
```
<br><br>

### Check Normality 

For the single-trial data, Shapiro-Wilk is not suitable, as it always returns a significant result for such large samples (additionally, it can handle only samples up to 5000). Hence, we have to rely on visual inspection (see above) and values of skewness and kurtosis. Values for skewness and kurtosis between -2 and +2 are considered acceptable in order to prove normal univariate distribution (George & Mallery, 2010).

```{r normality-single-trial-MFN}

normality_MFN <- round(data.frame(matrix(c(skewness(single_trial_data_clean$MFN_0_100_FCz),
                                          kurtosis(single_trial_data_clean$MFN_0_100_FCz),
                                          skewness(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz),
                                          kurtosis(single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",]$MFN_0_100_FCz),
                                          skewness(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz),
                                          kurtosis(single_trial_data_clean[single_trial_data_clean$response_type == "correct",]$MFN_0_100_FCz)),
                                        nrow=2, ncol = 3)),digits = 1)
rownames(normality_MFN) <- c("Skewness","Kurtosis")
colnames(normality_MFN) <- c("MFN", "ERN", "CRN")

my_table_template(normality_MFN, row_names = TRUE)
```
<br><br>

### Determine transformation

LMM analysis of MFN will be conducted on untransformed values, as it seems that the assumption of normally distributed residuals will be met. The appropriate transformation was determined using the Box–Cox procedure (Box & Cox, 1964). 

```{r MFN-determine-transformation, fig.width = 8, fig.height = 3}

# Arrange plots
par(mfrow = c(1, 3)) 

# Determine transformation of MFN by estimating optimal lambda using Box–Cox procedure
bc_MFN <- boxcox(MFN_0_100_FCz + 100 ~ 1, data = single_trial_data_clean)
optlambda_MFN <- bc_MFN$x[which.max(bc_MFN$y)]

# Determine transformation of ERN by estimating optimal lambda using Box–Cox procedure
bc_ERN <- boxcox(MFN_0_100_FCz + 100 ~ 1, data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",])
optlambda_ERN <- bc_ERN$x[which.max(bc_ERN$y)]

# Determine transformation of CRN by estimating optimal lambda using Box–Cox procedure
bc_CRN <- boxcox(MFN_0_100_FCz + 100 ~ 1, data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",])
optlambda_CRN <- bc_CRN$x[which.max(bc_CRN$y)]

# Reset plot layout
par(mfrow = c(1, 1)) 
```
For MFN (left plot), the optimal lambda is `r round(optlambda_MFN, digits = 2)`, suggesting that no transformation (for lambda = 1) is needed.
For ERN (middle plot), the optimal lambda is `r round(optlambda_ERN, digits = 2)`, suggesting that no transformation (for lambda = 1) is needed.
For CRN (right plot), the optimal lambda is `r round(optlambda_CRN, digits = 2)`, suggesting that no transformation (for lambda = 1) is needed.
<br><br>

### Split-half reliability

```{r permutation-split-half-reliability, cache = knitr_cache_enabled}

# Calculate permutation-based split-half internal consistency
# use ""invisible(capture.output())" to avoid having ugly console output in html
invisible(capture.output(split_half_reliability <- splithalf(data = single_trial_data_clean,
                                    outcome = "RT",
                                    score = "average",
                                    permutations = 5000,
                                    halftype = "random",
                                    var.RT = "MFN_0_100_FCz",
                                    var.trialnum = "trial",
                                    var.participant = "participant_id",
                                    var.condition = "response_type",
                                    conditionlist = c("correct","incorrect"),
                                    average = "mean")))

# Display permutation-based split-half internal consistency
my_table_template(split_half_reliability$final_estimates, caption = "Permutation-based split-half reliability")
```
The internal consitency of ERN and CRN was estimated using a permutation-based split-half approach (Parsons 2020) with 5000 random splits. The (Spearman-Brown corrected) split-half internal consistency of ERN and CRN are excellent. The columns SB_low and SB_high represent 95% confience intervall limits. The spearman-brown corrected reliability estimate for the ERN was .95, 95% CI [.93, .97], for CRN 1, 95% CI [.99, 1]. The splithalf package was built to deal with RTs. However, the principle should also apply to ERP values, so the results should be correct. However, I also calculated the odd-even split-half reliabilty to compare the results (see below).
<br><br>

```{r odd-even-split-half-reliability}

# Code odd and even trials for reliability 
single_trial_data_clean$oddeven <- single_trial_data_clean$trial %% 2
single_trial_data_clean$oddeven <- single_trial_data_clean$trial %% 2


# Calculate mean CRN for odd and even trials per participant and session
internal_consistency_CRN <- single_trial_data_clean[single_trial_data_clean$response_type == "correct",] %>%
  dplyr::group_by(participant_id, session, oddeven) %>% 
  dplyr::summarise(mean_CRN = mean(MFN_0_100_FCz, na.rm=TRUE)
)


# Calculate mean ERN for odd and even trials per participant and session
internal_consistency_ERN <- single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",] %>%
  dplyr::group_by(participant_id, session, oddeven) %>% 
  dplyr::summarise(mean_ERN = mean(MFN_0_100_FCz, na.rm=TRUE)
)


# Correlating scores from even and odd items
r_CRN <- cor.test(internal_consistency_CRN$mean_CRN[internal_consistency_CRN$oddeven==1], internal_consistency_CRN$mean_CRN[internal_consistency_CRN$oddeven==0])
r_ERN <- cor.test(internal_consistency_ERN$mean_ERN[internal_consistency_ERN$oddeven==1], internal_consistency_ERN$mean_ERN[internal_consistency_ERN$oddeven==0])


# Adjusting with the Spearman-Brown prophecy formula
r_CRN_SB <- (2 * r_CRN$estimate) / (1 + r_CRN$estimate)
r_ERN_SB <- (2 * r_ERN$estimate) / (1 + r_ERN$estimate)


# Display odd-even split-half reliability
oddeven_split_half_reliability <- matrix(c(r_CRN$estimate, r_ERN$estimate, r_CRN$conf.int[1], r_ERN$conf.int[1], 
                                           r_CRN$conf.int[2], r_ERN$conf.int[2], r_CRN_SB, r_ERN_SB), ncol=4)
colnames(oddeven_split_half_reliability) <- c("splithalf_raw", "splithalf_CI_lower_limit", "splithalf_CI_upper_limit", "splithalf_spearmanbrown")
rownames(oddeven_split_half_reliability) <- c("CRN", "ERN")
my_table_template(oddeven_split_half_reliability, row_names = TRUE, caption = "Odd-even split-half reliability")
```
Odd-even reliability for the ERN is also good. 
<br><br>

## Descriptive Statistics {.tabset}
***

### Means and CIs

```{r descriptive-statistics-table}

# Calculate descriptive statistics for MFN per condition
descriptive_statistics_MFN <- summarySEwithinO(
  data          = single_trial_data_clean,
  measurevar    = "MFN_0_100_FCz",
  withinvars    = c("response_type", "stimulation", "session"),
  betweenvars   = "group",
  idvar         = "participant_id", 
  conf.interval = .95) %>%
  # Format confidence interval column
  dplyr::mutate(
    ci_MFN = paste0("[", round(MFN_0_100_FCz - ci, digits = 2), 
                   ", ", round(MFN_0_100_FCz + ci, digits = 2), "]")) %>%
  # Round MFN means to two decimals
  dplyr::mutate_at("MFN_0_100_FCz", round, digits = 2) %>%    
  # Select columns to be displayed
  dplyr::select(c("group", "response_type", "stimulation", "session", "MFN_0_100_FCz", "ci_MFN", "ci"))



# Split and re-merge MFN table to display both groups next to each other
descriptive_statistics_MFN_display <-  split(descriptive_statistics_MFN, descriptive_statistics_MFN$group)
descriptive_statistics_MFN_display <-  left_join(descriptive_statistics_MFN_display$HC, descriptive_statistics_MFN_display$OCD, 
                                                 by = c("response_type", "stimulation", "session"))


# Display descriptive statistics for MFN (and select columns)
my_table_template(descriptive_statistics_MFN_display[,c(2:6,9:10)],
  caption = "MFN (in μV)",
  col_names = c("Response type", "Stimulation", "Session", "M", "95% CI", "M", "95% CI"),
  header_above_config = c(" " = 3, "HC" = 2, "OCD" = 2),
  footnote_config = c(general = "Confidence intervals are adjusted for within-participant designs as described by Morey (2008).")
)



# Calcuate means and CIs adjusted for within-participant factors (without session) - for plots
descriptive_statistics_MFN_no_session <- summarySEwithinO(
  data          = single_trial_data_clean,
  measurevar    = "MFN_0_100_FCz",
  withinvars    = c("response_type", "stimulation"),
  betweenvars   = "group",
  idvar         = "participant_id", 
  conf.interval = .95
)
```
<br><br>

### Raincloud plot {.active}

```{r raincloud-plot, fig.width = 10, fig.height = 6, fig.cap = "Note. Response-locked ERP (ERN, CRN; 0-100 ms at FCz) in the flanker task is shown as a function of response type, stimulation condition, and group. Means and 95% confidence intervals (= lines at violin plot bottom) were calculated based on single-trial data. Boxplots and violin plots are based on data aggregated by subject. CIs are adjusted for within-participant designs as described by Morey (2008)."}


# define facet labels
response_type.labs <- c("CRN", "ERN")
names(response_type.labs) <- c("correct", "incorrect")


# From JB: "Raincloud plots (Allen et al., 2019) show means and 95% CIs calculated with the summarySEwithin function (Morey, 2008) on single trial data, and points, and distributions for data aggregated by subject"

# Create raincloud plot MFN 
plot_MFN_raincloud <- ggplot() +
  # Add aggregated distribution, boxplot and data points
  geom_flat_violin(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group), position = position_nudge(x = .1, y = 0), 
                   adjust = 1.5, trim = FALSE, alpha = .5, colour = NA)+
  geom_point(data = df_aggregated_per_subject_MFN, aes(x = as.numeric(stimulation)-.15, y = MFN, colour = group),
             position = position_jitter(width = .05), size = 1, shape = 20)+
  geom_boxplot(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group),
               outlier.shape = NA, alpha = .5, width = .1, colour = "black")+
  # Add single-trial mean + CI
  geom_point(data = descriptive_statistics_MFN_no_session, aes(x = as.numeric(stimulation)+0.1, y = MFN_0_100_FCz, colour = group), 
             shape = 95, size = 6) +
  geom_errorbar(data = descriptive_statistics_MFN_no_session, aes(x = as.numeric(stimulation)+0.1, ymax = MFN_0_100_FCz + ci, ymin = MFN_0_100_FCz - ci), 
                colour = "black", width = 0) +
  # Add style
  scale_colour_manual(values = my_figure_colors, name = "Group:") +
  scale_fill_manual(values = my_figure_colors, name = "Group:") +
  facet_wrap(~response_type,labeller = labeller(response_type = response_type.labs)) + 
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])") +
  my_figure_theme 


# Save plot
 ggsave("./figures/figure_MFN_raincloud.tiff", width = 20, height = 25, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN_raincloud
```
<br><br>

### Plot without session

```{r descriptive-statistics-plot-rt-acc, fig.width = 8, fig.height = 7, fig.cap = "Note. Response-locked ERP (ERN, CRN; 0-100 ms at FCz) in the flanker task is shown as a function of response type, stimulation condition, and group. Means and 95% confidence intervals (shown in orange/red) were calculated based on single-trial data. Boxplots are based on data aggregated by subject. CIs are adjusted for within-participant designs as described by Morey (2008)."}

# Create plot MFN 
plot_MFN <- ggplot() +
  geom_boxplot(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group), outlier.size =0.3)+
  geom_point(data = descriptive_statistics_MFN_no_session, aes(x = stimulation, y = MFN_0_100_FCz, colour = group), 
             position = position_dodge(width = 0.7), shape = 15, size = 1) +
  geom_errorbar(data = descriptive_statistics_MFN_no_session, aes(x = stimulation, ymax = MFN_0_100_FCz + ci, ymin = MFN_0_100_FCz - ci, colour = group),
                position = position_dodge(width = 0.7), width = 0, size = 0.5) +
  geom_line(data = descriptive_statistics_MFN_no_session, aes(x = stimulation, y = MFN_0_100_FCz, group = group, color = group), 
            position = position_dodge(width = 0.7), linetype = 3, size = 0.5) +
  scale_colour_manual(values = c("#b23f00", "#ff9b64"), name = "Group:") +
  scale_fill_manual(values = my_figure_colors, name = "Group:") +
  facet_wrap(~response_type, nrow = 1) +
  my_figure_theme + 
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])")


# Save plot
ggsave("./figures/figure_MFN.tiff", width = 12, height = 12, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN
``` 
<br><br>

### Plot with session

```{r descriptive-statistics-plot-including-session, fig.width = 10, fig.height = 7, fig.cap = "Note. Response-locked ERP (ERN, CRN; 0-100 ms at FCz) in the flanker task is shown as a function of response type, stimulation condition, group, and session. Means and 95% confidence intervals (shown in orange/red) were calculated based on single-trial data. Boxplots are based on data aggregated by subject. CIs are adjusted for within-participant designs as described by Morey (2008)."}

# Create plot MFN 
plot_MFN_session <- ggplot() +
  geom_boxplot(data = df_aggregated_per_subject_MFN, aes(x = stimulation, y = MFN, fill = group), outlier.size =0.3)+
  geom_point(data = descriptive_statistics_MFN, aes(x = stimulation, y = MFN_0_100_FCz, colour = group), 
             position = position_dodge(width = 0.7), shape = 15, size = 1) +
  geom_errorbar(data = descriptive_statistics_MFN, aes(x = stimulation, ymax = MFN_0_100_FCz + ci, ymin = MFN_0_100_FCz - ci, colour = group),
                position = position_dodge(width = 0.7), width = 0, size = 0.5) +
  geom_line(data = descriptive_statistics_MFN, aes(x = stimulation, y = MFN_0_100_FCz, group = group, color = group), 
            position = position_dodge(width = 0.7), linetype = 3, size = 0.5) +
  scale_colour_manual(values = c("#b23f00", "#ff9b64"), name = "Group:") +
  scale_fill_manual(values = my_figure_colors, name = "Group:") +
  facet_wrap(~response_type + session, nrow = 1) +
  my_figure_theme + 
  labs(x = "\nStimulation condition", y = "MFN (mean amplitude 0-100 ms at FCz [μV])") 


# Save plot
 ggsave("./figures/figure_MFN_session.tiff", width = 20, height = 25, units = "cm", dpi=600, compression = "lzw")


# Display plot
plot_MFN_session
```  
<br><br>

## LMM Analyses
***

MFN/ERN/CRN were modeled using a linear mixed-effects models (LMMs). <br><br>

**Fixed effects**

*Group (HC, OCD), stimulation (verum, sham), and response type (correct, incorrect)* were specified as fixed factors. I thought about including also session as fixed effect. But this was not stated in preregistration and is of no real interest. Fixed effects were coded using effect coding (this equals sliding difference contrasts for two levels for factors with two levels), such that the intercept reflects the grand mean across all conditions and differences in means between factor levels are tested. Fixed effects were not eliminated using model comparison techniques because they correspond to the original experimental design and a priori hypotheses. <br><br>


**Random effects**

Participants were specified as random factors. The random-effects structure for each model was determined based on the procedure proposed by Bates, Kliegl, et al. (2015). We started with the maximal random-effects structure  that was justified by the design, including random intercepts for participants, as well as random slopes for all main effects and interactions specified as fixed effects. If the model with the maximal random-effects structure would not converge, correlations of the random terms were set to zero. We performed a principal components analysis on the random-effects variance–covariance estimates to determine the number of components supported by the data and removed random effects explaining zero variance to prevent overparametrization (Matuschek et al., 2017).

```{r MFN-LMM-contrast-coding}

# Define contrasts (sliding difference contrasts)
contrasts(single_trial_data_clean$stimulation)   <- contr.sdif(2)
contrasts(single_trial_data_clean$group)         <- contr.sdif(2)
contrasts(single_trial_data_clean$response_type) <- contr.sdif(2)
contrasts(single_trial_data_clean$session)       <- contr.sdif(2)
contrasts(single_trial_data_clean$stimulus_type) <- contr.sdif(2)
contrasts(single_trial_data_clean$medication)    <- contr.sdif(2)


# Add contrasts as numerical covariates via model matrix* (specify all possible contasts for now)
model_matrix <- model.matrix(~ stimulation * group * response_type, single_trial_data_clean)


# Attach the model matrix (16 columns) to the dataframe
single_trial_data_clean[, (ncol(single_trial_data_clean) + 1):(ncol(single_trial_data_clean) + 8)] <- model_matrix


# Assign descriptive names to the contrasts
names(single_trial_data_clean)[(ncol(single_trial_data_clean) - 7):ncol(single_trial_data_clean)] <- c("Grand Mean", "verum_sham", "OCD_HC", "incorrect_correct", "verum_sham:OCD_HC", "verum_sham:incorrect_correct", "OCD_HC:incorrect_correct", "verum_sham:OCD_HC:incorrect_correct")


# *Note: For the random effects, we needed to enter the separate random effect terms in the models to enable
# double-bar notation (||). This allows fitting a model that sets correlations of the random terms to zero.
```
<br><br>

### LMM for MFN {.tabset}

#### Model

This is the overall model, including error and correct trials. This model will be reported before reporting the separate models for ERN/CRN; as it also shows the overall group effect and stimulation effect. 

```{r LMM-MFN, cache = knitr_cache_enabled}

# Run model with maximal random-effects structure
LMM_MFN <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * incorrect_correct +
  (1 + verum_sham + incorrect_correct + verum_sham:incorrect_correct | participant_id),
data = single_trial_data_clean,
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_MFN) # Model does converge
# isSingular(LMM_MFN) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_MFN)) # All terms explain variance (> 0.5%)


# Display results (fixed effects)
tab_model(LMM_MFN,
  dv.labels = "MFN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
There is a main effect of stimulation, group, and response type. 
<br><br>

#### Assumption checks 

```{r LMM-MFN-assumptions, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# Check model assumptions
performance::check_model(LMM_MFN, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_MFN)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_MFN, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_MFN, effects = "random")
```

* **Assumption 1: Independence of Data Points / Absence of collinearity -> Is OK**
    + Are predictors not highly correlated?
    + Multicollinearity plot shows only low correlations 

* **Assumption 2: Normality of Residuals -> Is Not OK???** 
    + Are residuals approximately normally distributed?
    + Q-Q plot and density plot look not so great; Q-Q plot quite a bit off at the extremes 
    + It is debated whether this is problematic at all; and violation does not seem so bad, so maybe not worry about it? 

* **Assumption 3: Linearity -> Is OK** 
    + Is the dependent variable linearly related to the fixed factors, random factors, and covariates?
    + Plot of the residuals against the fitted values shows a random scatter pattern, no nonlinear or curvy pattern 

* **Assumption 4: Homogeneity of Residual Variance (Heteroscedasticity) -> Is OK???**
    + Have residuals constant variance across the range of the predicted values?
    + Plot of the residuals against the fitted values shows an even spread around the centered line; but written output says this is not ok

* **Assumption 5: Absence of Influential Data Points -> Is OK** 
    + Are there are no influential values? 
    + Cook's distance plot looks fine (for large N, Cook's distances should be below 1) and written output says there are no outliers 

* **Assumption 6: Normality of Random Effects -> Is OK**
    + Are random effects approximately normally distributed?
    + Written output says this is (mostly) ok 
<br><br>

### LMM for ERN / CRN {.tabset}

#### Model

```{r LMM-ERN-CRN, cache = knitr_cache_enabled}

# ERN
LMM_ERN <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_ERN) # Model does converge
# isSingular(LMM_ERN) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_ERN)) # All terms explain variance (> 0.5%)


tab_model(LMM_ERN,
  dv.labels = "ERN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN
LMM_CRN <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


# Check model output
# summary(LMM_CRN) # Model does converge
# isSingular(LMM_CRN) # Check for singular model fit (i.e., dimensions of the variance-covariance matrix have been estimated as exactly zero): FALSE


# Check PCA of random-effects variance-covariance estimates
# summary(rePCA(LMM_CRN)) # All terms explain variance


tab_model(LMM_CRN,
  dv.labels = "CRN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
There is a trend for a higher ERN in OCD compared to HC (p = 0.54) [NOTE: with REML = FALSE in the model, p = 0.049862]. There also is a trend for a higher CRN in OCD compared to HC (p = 0.068). For CRN, there is an effect of stimulation, with smaller (i.e., less negative) CRN in the verum stimulation compared to the sham condition. There is no stimulation effect on ERN. However, *when excluding participants with metal on head, there is a trend or even a significant effect* (see section covariates).
<br><br>

#### Assumption checks ERN model

```{r LMM-ERN-CRN-assumptions1, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# ERN check model assumptions
performance::check_model(LMM_ERN, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_ERN)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_ERN, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_ERN, effects = "random")
```

Notes for assumption check would be the same as written for the MFN model.
<br><br>

#### Assumption checks CRN model

```{r LMM-ERN-CRN-assumptions2, fig.width = 20, fig.height = 15, cache = knitr_cache_enabled}

# CRN check model assumptions
performance::check_model(LMM_CRN, panel = TRUE)

# In addition to plots, print verbal output for some assumption tests to facilitate conclusion
print("# Check for heteroscedasticity")
performance::check_heteroscedasticity(LMM_CRN)

print("# Check for influential observations (Cook's distance)")
performance::check_outliers(LMM_CRN, effects = "random")

print("# Check for normal distributed random effects")
performance::check_normality(LMM_CRN, effects = "random")
```

Notes for assumption check would be the same as written for the MFN model.
<br><br>

#### Check covariates

```{r LMM-ERN-CRN-covariates, cache = knitr_cache_enabled}

# ERN check covariate session
LMM_ERN_session <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * session  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_session,
  dv.labels = "ERN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate session
LMM_CRN_session <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * session  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_session,
  dv.labels = "CRN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of errors (predictor was z standardized)
LMM_ERN_number_errors <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_number_errors,
  dv.labels = "ERN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)

 
# CRN check covariate number of errors (predictor was z standardized)
LMM_CRN_number_errors <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_number_errors,
  dv.labels = "CRN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of feedback faster (predictor was z standardized)
LMM_ERN_number_feedback_faster <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_number_feedback_faster,
  dv.labels = "ERN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate number of feedback faster (predictor was z standardized)
LMM_CRN_number_feedback_faster <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_number_feedback_faster,
  dv.labels = "CRN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate stimulus type
LMM_ERN_stimulus_type <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * stimulus_type  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_stimulus_type,
  dv.labels = "ERN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate stimulus_type
LMM_CRN_stimulus_type <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * stimulus_type  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_stimulus_type,
  dv.labels = "CRN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate medication
LMM_ERN_medication <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * medication  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_medication,
  dv.labels = "ERN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate medication
LMM_CRN_medication <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC * medication  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_medication,
  dv.labels = "CRN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only unmedicated participants
LMM_ERN_unmedicated <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC +  
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_unmedicated,
  dv.labels = "ERN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only unmedicated participants
LMM_CRN_unmedicated <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_unmedicated,
  dv.labels = "CRN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only participants with no metal on head (P_02 retainer, C_06 piercing left ear)
LMM_ERN_no_metal <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC +  
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$participant_id != "P_02" &
                               single_trial_data_clean$participant_id != "C_06",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_no_metal,
  dv.labels = "ERN [μV], only participants with no metal on head", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only participants with no metal on head (P_02 retainer, C_06 piercing left ear)
LMM_CRN_no_metal <- lmer(MFN_0_100_FCz ~ verum_sham * OCD_HC + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$participant_id != "P_02" &
                               single_trial_data_clean$participant_id != "C_06",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_no_metal,
  dv.labels = "CRN [μV], only  participants with no metal on head", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>

**Covariates**

The purpose for including the covariates was to see how the effects change when controlling for the overall effect of the covariate. Thus, covariates were included only as fixed factor, not as random term. I first included the covariates as main effect only, not allowing any interactions with stimulation or group. However, inspecting the interactions as well might lead to new, important insights. These models are reported above. 
<br><br>

* **ERN group difference**: Remains a trend when including the covariate session, number of errors, number of feedback faster, or stimulus type in the model. Turns non-significant when including the variable medication in the model. 

* **CRN group difference**: Remains a trend when including the covariate session, number of errors, number of feedback faster, or stimulus type in the model. Turns non-significant when including the variable medication in the model. 

* **ERN stimulation effect**: Remains non-significant in all models.

* **CRN stimulation effect**: Remains significant when including the covariate session, number of errors,  stimulus type, or medication in the model. Turns to a trend when including the variable number of feedback faster in the model (but only when allowing interactions with the covariate, not when only allowing its main effect). 

<br>
Update: Allowing the interactions compared to the model specifying only the main effect of the covariate does not change model results for the covariates session, stimulus type and medication. For the covariates number of errors and number of feedback faster, the only change is that the ERN stimulation effect changes much further away from a trend when allowing the interactions (from p = .18 to .41 and p = .18 to .39, respectively).
<br><br>

**Subgroup analyses**

When including only unmedicated patients, there is no ERN group difference anymore, no CRN group trend anymore and no CRN stimulation effect anymore (possibly due to reduced power). *When including only participants with no metal on head (P_06 had retainer, C_02 piercing left ear), the ERN group difference turns to a trend but ERN stimulation effect also turns to a trend or even significant* (see below). Excluding P_02 and C_02 would be closest to preregistration (exclude participant with their matchtes). Metal for C_06 is not likely to have had an influence. The CRN group difference trend and stimulation effect is not really affected by any of the metal-exclusion variations stated below. 
<br><br>
ERN group difference

* without P_02                p = .082

* without P_02+C_02           p = .079

* without P_02+C_06           p = .090

* without P_02+C_02+C_06+P_06 p = .086

<br><br>
ERN stimulation effect

* without P_02                p = .061//.056 when REML=FALSE

* without P_02+C_02           p = .052//.047 when REML=FALSE

* without P_02+C_06           p = .098

* without P_02+C_02+P_06+C_06 p = .063

<br><br>

### LMM for ERN / CRN (nested) {.tabset}

#### Model

```{r LMM-ERN-CRN-per-group, cache = knitr_cache_enabled}

# ERN
LMM_ERN_group <- lmer(MFN_0_100_FCz ~ group/stimulation  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# model is not singular and all random terms explain variance, however according to summary output it seems to fail to converge?


tab_model(LMM_ERN_group,
  dv.labels = "ERN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN
LMM_CRN_group <- lmer(MFN_0_100_FCz ~ group/stimulation  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)


tab_model(LMM_CRN_group,
  dv.labels = "CRN [μV]", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = TRUE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
Also for the separate groups, there is no evidence for an effect of stimulation on ERN. According to the plots above it seemed that at least in the HC group, there is a smaller (i.e., less negative) ERN in the verum than in the sham condition. But this is not reflected in the LMM.
For the CRN, there was a main effect of stimulation (see above). When testing this effect separately in the groups, a stimulation effect on CRN is evident for the OCD but not for the HC group. The higher order interaction group * stimulation was not significant (p = .112).
<br><br>

#### Assumption checks 

Is same as in non-nested models (tab LMM separately for ERN / CRN)
<br><br>

#### Check covariates

```{r LMM-ERN-CRN-per-group-covariates, cache = knitr_cache_enabled}

# ERN check covariate session
LMM_ERN_group_session <- lmer(MFN_0_100_FCz ~ group/stimulation * session  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_session,
  dv.labels = "ERN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate session
LMM_CRN_group_session <- lmer(MFN_0_100_FCz ~ group/stimulation * session  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_session,
  dv.labels = "CRN [μV], covariate session", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of errors (predictor was z standardized)
LMM_ERN_group_number_errors <- lmer(MFN_0_100_FCz ~ group/stimulation * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_number_errors,
  dv.labels = "ERN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate number of errors (predictor was z standardized)
LMM_CRN_group_number_errors <- lmer(MFN_0_100_FCz ~ group/stimulation * number_errors_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_number_errors,
  dv.labels = "CRN [μV], covariate number of errors", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate number of feedback faster (predictor was z standardized)
LMM_ERN_group_number_feedback_faster <- lmer(MFN_0_100_FCz ~ group/stimulation * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_number_feedback_faster,
  dv.labels = "ERN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate number of feedback faster (predictor was z standardized)
LMM_CRN_group_number_feedback_faster <- lmer(MFN_0_100_FCz ~ group/stimulation * number_feedback_faster_standardized  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_number_feedback_faster,
  dv.labels = "CRN [μV], covariate number of feedback faster", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate stimulus type
LMM_ERN_group_stimulus_type <- lmer(MFN_0_100_FCz ~ group/stimulation * stimulus_type  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_stimulus_type,
  dv.labels = "ERN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate stimulus_type
LMM_CRN_group_stimulus_type <- lmer(MFN_0_100_FCz ~ group/stimulation * stimulus_type  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_stimulus_type,
  dv.labels = "CRN [μV], covariate stimulus type", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN check covariate medication
LMM_ERN_group_medication <- lmer(MFN_0_100_FCz ~ group/stimulation * medication  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_medication,
  dv.labels = "ERN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN check covariate medication
LMM_CRN_group_medication <- lmer(MFN_0_100_FCz ~ group/stimulation * medication  +
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_medication,
  dv.labels = "CRN [μV], covariate medication", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only unmedicated participants
LMM_ERN_group_unmedicated <- lmer(MFN_0_100_FCz ~ group/stimulation +  
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_unmedicated,
  dv.labels = "ERN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only unmedicated participants
LMM_CRN_group_unmedicated <- lmer(MFN_0_100_FCz ~ group/stimulation + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$medication == "no",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_unmedicated,
  dv.labels = "CRN [μV], only unmedicated participants", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# ERN include only participants with no metal on head (P_02 retainer, C_06 piercing left ear)
LMM_ERN_group_no_metal <- lmer(MFN_0_100_FCz ~ group/stimulation +  
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "incorrect" & single_trial_data_clean$participant_id != "P_02" &
                               single_trial_data_clean$participant_id != "C_06",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_ERN_group_no_metal,
  dv.labels = "ERN [μV], only participants with no metal on head", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)


# CRN  include only participants with no metal on head (P_02 retainer, C_06 piercing left ear)
LMM_CRN_group_no_metal <- lmer(MFN_0_100_FCz ~ group/stimulation  + 
  (1 + verum_sham | participant_id),
data = single_trial_data_clean[single_trial_data_clean$response_type == "correct" & single_trial_data_clean$participant_id != "P_02" &
                               single_trial_data_clean$participant_id != "C_06",],
REML = TRUE,
control = lmerControl(optimizer = "bobyqa")
)
# Convergence, singulatrity, PCA checked, all ok
tab_model(LMM_CRN_group_no_metal,
  dv.labels = "CRN [μV], only  participants with no metal on head", show.stat = TRUE, show.icc = TRUE, show.r2 = TRUE, 
  show.re.var = FALSE, show.ngroups = TRUE, string.est = "b", string.stat = "t value", 
  string.ci = "95 % CI", string.p = "p value",  p.val = "satterthwaite", wrap.labels = 80, digits.re = 3
)
```
<br><br>
**Covariates**

For further infos, see notes in section non-nested ERN-CRN models.
<br><br>

* **ERN group difference**: See notes in section  non-nested ERN-CRN models.

* **CRN group difference**: See notes in section  non-nested ERN-CRN models.

* **ERN stimulation effect in HC/OCD**: For HC and OCD remains non-significant in all models.

* **CRN stimulation effect in HC/OCD**: For HC remains non-significant in all models. For OCD remains significant in all models. 

<br>
Update: Allowing the interactions compared to the model specifying only the main effect of the covariate does not change model results for the covariates session, stimulus type and medication. For the covariates number of errors and number of feedback faster, the only change is that the ERN stimulation effect in HC changes much further away from a trend when allowing the interactions (from p = .18 to .33 and p = .22 to .45, respectively).
<br><br>

**Subgroup analyses**

When including only unmedicated patients, there is no ERN group difference anymore, no CRN group trend anymore and no CRN stimulation effect in OCD anymore (possibly due to reduced power). When including only participants with no metal on head (P_06 had retainer, C_02 piercing left ear), the ERN group difference turns to a trend; there still is no ERN stimulation effect separately for the groups (but overall; see non-nested model). Excluding P_02 and C_02 would be closest to preregistration (exclude participant with their matchtes). Metal for C_06 is not likely to have had an influence. The CRN group difference trend and stimulation effect is not affected by any of the metal-exclusion variations stated below. 
<br><br>

## ANOVAs {.tabset}
***

### ANOVAs

To facilitate comparison with previously reported results obtained using a similar task and aggregation-based analyses (Rainhart & Woodman 2014), MFN/ERN/CRN were additionally analyzed with repeated-measures analyses of variance (ANOVAs) including the within-participant factors stimulation (verum, sham), group (OCD, HC), and (only for MRN) response type (correct, incorrect). No  Greenhouse–Geisser correction was applied, as no factor had more than two levels. As can be seen below, the ANOVAs yielded the same results as obtained with mixed-effects modeling with respect to all effects. The group difference in ERN magnitude emerged in the LMMs as a statistical trend only (p = .054), in the ANOVA it is significant (p = .048). 

```{r ANOVAs}

# Due to the afex package, contrasts are automatically set to effect-coding (contr.sum). Afex package 
# also checks sphericity assumptions and automatically corrects for any violations if necessary.


# ANOVA overall
anova_MFN <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN", 
  data   = df_aggregated_per_subject_MFN,
  within = c("stimulation", "response_type"),
  between= c("group"),
  observed = c("group")
)


# ANOVA ERN
anova_ERN <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN", 
  data   = df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$response_type == "incorrect",],
  within = c("stimulation"),
  between= c("group"),
  observed = c("group")
)



# ANOVA CRN
anova_CRN <- aov_ez(
  id     = "participant_id", 
  dv     = "MFN", 
  data   = df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$response_type == "correct",],
  within = c("stimulation"),
  between= c("group"),
  observed = c("group")
)


# Display ANOVA results
my_table_template(nice(anova_MFN, MSE = FALSE), caption = "MFN")
my_table_template(nice(anova_ERN, MSE = FALSE), caption = "ERN")
my_table_template(nice(anova_CRN, MSE = FALSE), caption = "CRN")
```
<br><br>

### Pairwise comparisons

As no significant main effect with > 2 levels or interaction effect was present, no post hoc pairwise comparisons would need to be conducted. However, the stimulation effect on ERN in the separate groups may be seen as pre-planned contrast that we want to test. For these effects, I calculated two-tailed paired *t* tests with Holm–Bonferroni *p* value adjustments. There is still no stimulation effect on ERN in the two groups. The effect on CRN is present in the OCD group. In the sham condition, the CRN is higher (more negative) in the OCD group; in the verum condition there is no evidence for such group difference anymore.

```{r ANOVAs-pairwise-tests}

# Use multivariate model for all follow-up tests to adequately control for violations of sphericity
afex_options(emmeans_model = "multivariate")


# Pairwise t tests
pairwise_ERN    <- summary(pairs(emmeans(anova_ERN, "stimulation", by = "group"), adjust = "holm"))
pairwise_CRN_1  <- summary(pairs(emmeans(anova_CRN, "stimulation", by = "group"), adjust = "holm"))
pairwise_CRN_2  <- summary(pairs(emmeans(anova_CRN, "group", by = "stimulation"), adjust = "holm"))



# Add Cohen's dz (CIs for d could be added if needed, as it can be returned by the "t_to_d" function)
pairwise_ERN$cohens_dz   <- round(t_to_d(pairwise_ERN$t.ratio,   pairwise_ERN$df,   paired = TRUE)[1], digits = 2)
pairwise_CRN_1$cohens_dz <- round(t_to_d(pairwise_CRN_1$t.ratio, pairwise_CRN_1$df, paired = TRUE)[1], digits = 2)
pairwise_CRN_2$cohens_dz <- round(t_to_d(pairwise_CRN_2$t.ratio, pairwise_CRN_2$df, paired = TRUE)[1], digits = 2)

# Display results 
my_table_template(pairwise_ERN, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "ERN: Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 


my_table_template(pairwise_CRN_1, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "CRN: Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 


my_table_template(pairwise_CRN_2, 
                  digits = c(0, 0, 2, 2, 0, 2, 3, 2),
                  caption = "CRN: Stimulation Effect Within Groups",
                  footnote = "P values are adjusted with Holm–Bonferroni method.") 
```
### Simple t tests

Same results as with pairwise comparisons via emmeans and p value adjustment: There is still no stimulation effect on ERN in the two groups. The effect on CRN is present in the OCD group. Note that here the p values are not adjusted for multiple comparisons yet.

```{r t-tests}

# Stimulation effect on ERN in OCD -> n.s.
ERN_OCD <- t.test(MFN ~ stimulation,
                  data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "OCD" & 
                                                     df_aggregated_per_subject_MFN$response_type == "incorrect",],
                  paired=TRUE)


# Stimulation effect on ERN in HC -> n.s.
ERN_HC <- t.test(MFN ~ stimulation,
                 data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "HC" & 
                                                    df_aggregated_per_subject_MFN$response_type == "incorrect",],
                 paired=TRUE)


# Stimulation effect on CRN in OCD -> sign. 
CRN_OCD <- t.test(MFN ~ stimulation,
                  data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "OCD" & 
                                                     df_aggregated_per_subject_MFN$response_type == "correct",],
                  paired=TRUE)


# Stimulation effect on CRN in HC -> n.s. 
CRN_HC <- t.test(MFN ~ stimulation,
                 data=df_aggregated_per_subject_MFN[df_aggregated_per_subject_MFN$group == "HC" & 
                                                    df_aggregated_per_subject_MFN$response_type == "correct",],
                 paired=TRUE)


# Mke nice table for display
library(broom)
library(purrr)

tab <- map_df(list(ERN_OCD, ERN_HC,  CRN_OCD, CRN_HC), tidy)
contrast = c("OCD ERN: sham-verum", "HC ERN: sham-verum", "OCD CRN: sham-verum", "HC CRN: sham-verum")
my_table_template(cbind(contrast, tab[c("estimate", "statistic", "p.value")]))
```
<br><br>

### Assumption checks

```{r ANOVAs-assumptions, fig.height = 6}

# Get residuals
residuals_anova_MFN      <- as.data.frame(anova_MFN$lm$residuals)
residuals_anova_ERN      <- as.data.frame(anova_ERN$lm$residuals)
residuals_anova_CRN      <- as.data.frame(anova_CRN$lm$residuals)


# Plot residuals
hist_residuals_anova_MFN <- ggplot(gather(residuals_anova_MFN, cols, value), aes(x = value)) + 
  geom_histogram(color = my_figure_colors[2], fill = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "Histogram Residuals MFN") + my_figure_theme

qqplot_residuals_anova_MFN <- ggplot(gather(residuals_anova_MFN, cols, value), aes(sample = value)) + 
  stat_qq(color = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "QQ-Plot Residuals MFN") + my_figure_theme

hist_residuals_anova_ERN <- ggplot(gather(residuals_anova_ERN, cols, value), aes(x = value)) + 
  geom_histogram(color = my_figure_colors[2], fill = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "Histogram Residuals ERN") + my_figure_theme

qqplot_residuals_anova_ERN <- ggplot(gather(residuals_anova_ERN, cols, value), aes(sample = value)) + 
  stat_qq(color = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "QQ-Plot Residuals ERN") + my_figure_theme

hist_residuals_anova_CRN <- ggplot(gather(residuals_anova_CRN, cols, value), aes(x = value)) + 
  geom_histogram(color = my_figure_colors[2], fill = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "Histogram Residuals CRN") + my_figure_theme

qqplot_residuals_anova_CRN <- ggplot(gather(residuals_anova_CRN, cols, value), aes(sample = value)) + 
  stat_qq(color = my_figure_colors[1]) + 
  facet_wrap(.~cols) + labs(title = "QQ-Plot Residuals CRN") + my_figure_theme

ggdraw() +
  draw_plot(hist_residuals_anova_MFN,       x =  0,   y = .6, width = .5, height = .4) +
  draw_plot(qqplot_residuals_anova_MFN,     x =  .5,  y = .6, width = .5, height = .4) +
  draw_plot(hist_residuals_anova_ERN,       x =  0,   y = .3, width = .5, height = .3) +
  draw_plot(qqplot_residuals_anova_ERN,     x =  .5,  y = .3, width = .5, height = .3) +
  draw_plot(hist_residuals_anova_CRN,       x =  0,   y = 0,  width = .5, height = .3) +
  draw_plot(qqplot_residuals_anova_CRN,     x =  .5,  y = 0,  width = .5, height = .3) 


# Test normality of residuals
print("# ANOVA MFN: Normality of Residuals with Shapiro Wilk Test")
do.call(rbind, lapply(residuals_anova_MFN[,], function(x) shapiro.test(x)["p.value"]))

print("# ANOVA ERN: Check Normality of Residuals with Shapiro Wilk Test")
do.call(rbind, lapply(residuals_anova_ERN[,], function(x) shapiro.test(x)["p.value"]))

print("# ANOVA CRN: Check Normality of Residuals with Shapiro Wilk Test")
do.call(rbind, lapply(residuals_anova_CRN[,], function(x) shapiro.test(x)["p.value"]))
```

* **Assumption #1: Dependent variable interval or ratio variable -> Is OK**

* **Assumption #2: Balanced design** (each subject has to have a value in each condition) **-> Is OK**

* **Assumption #3: No dependency in the scores between participants** (dependency can exist only across scores for individuals) **-> Is OK**

* **Assumption #4: Residuals** of the dependent variable in each level of the within-subjects factor are approximately **normally distributed -> Is OK** (see above; for incorrect verum condition only small deviation)**

* **Assumption #5: Sphericity** (only relevant for withlin-subject factors with > 2 levels) (afex package automatically corrects (Greenhouse Geisser) for any violations if necessary) **-> Is OK**

<br><br>

